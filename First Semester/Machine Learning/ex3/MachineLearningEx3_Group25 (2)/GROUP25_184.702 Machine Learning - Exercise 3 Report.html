<!DOCTYPE html>

<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="mobile-web-app-capable" content="yes">
    <title>
        184.702 Machine Learning - Exercise 3 Report - HackMD
    </title>
    <link rel="icon" type="image/png" href="https://hackmd.io/favicon.png">
    <link rel="apple-touch-icon" href="https://hackmd.io/apple-touch-icon.png">

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/ionicons/2.0.1/css/ionicons.min.css" integrity="sha256-3iu9jgsy9TpTwXKb7bNQzqWekRX7pPK+2OLj3R922fo=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/octicons/3.5.0/octicons.min.css" integrity="sha256-QiWfLIsCT02Sdwkogf6YMiQlj4NE84MKkzEMkZnMGdg=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.1/themes/prism.min.css" integrity="sha256-vtR0hSWRc3Tb26iuN2oZHt3KRUomwTufNIf5/4oeCyg=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@hackmd/emojify.js@2.1.0/dist/css/basic/emojify.min.css" integrity="sha256-UOrvMOsSDSrW6szVLe8ZDZezBxh5IoIfgTwdNDgTjiU=" crossorigin="anonymous" />
    <style>
        @import url(https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,500,500i|Source+Code+Pro:300,400,500|Source+Sans+Pro:300,300i,400,400i,600,600i|Source+Serif+Pro&subset=latin-ext);.hljs{display:block;background:#fff;padding:.5em;color:#333;overflow-x:auto}.hljs-comment,.hljs-meta{color:#969896}.hljs-emphasis,.hljs-quote,.hljs-string,.hljs-strong,.hljs-template-variable,.hljs-variable{color:#df5000}.hljs-keyword,.hljs-selector-tag,.hljs-type{color:#a71d5d}.hljs-attribute,.hljs-bullet,.hljs-literal,.hljs-number,.hljs-symbol{color:#0086b3}.hljs-built_in,.hljs-builtin-name{color:#005cc5}.hljs-name,.hljs-section{color:#63a35c}.hljs-tag{color:#333}.hljs-attr,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-id,.hljs-selector-pseudo,.hljs-title{color:#795da3}.hljs-addition{color:#55a532;background-color:#eaffea}.hljs-deletion{color:#bd2c00;background-color:#ffecec}.hljs-link{text-decoration:underline}.markdown-body{font-size:16px;line-height:1.5;word-wrap:break-word}.markdown-body:after,.markdown-body:before{display:table;content:""}.markdown-body:after{clear:both}.markdown-body>:first-child{margin-top:0!important}.markdown-body>:last-child{margin-bottom:0!important}.markdown-body a:not([href]){color:inherit;text-decoration:none}.markdown-body .absent{color:#c00}.markdown-body .anchor{float:left;padding-right:4px;margin-left:-20px;line-height:1}.markdown-body .anchor:focus{outline:none}.markdown-body blockquote,.markdown-body dl,.markdown-body ol,.markdown-body p,.markdown-body pre,.markdown-body table,.markdown-body ul{margin-top:0;margin-bottom:16px}.markdown-body hr{height:.25em;padding:0;margin:24px 0;background-color:#e7e7e7;border:0}.markdown-body blockquote{font-size:16px;padding:0 1em;color:#777;border-left:.25em solid #ddd}.markdown-body blockquote>:first-child{margin-top:0}.markdown-body blockquote>:last-child{margin-bottom:0}.markdown-body kbd,.popover kbd{display:inline-block;padding:3px 5px;font-size:11px;line-height:10px;color:#555;vertical-align:middle;background-color:#fcfcfc;border:1px solid #ccc;border-bottom-color:#bbb;border-radius:3px;box-shadow:inset 0 -1px 0 #bbb}.markdown-body .loweralpha{list-style-type:lower-alpha}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{margin-top:24px;margin-bottom:16px;font-weight:600;line-height:1.25}.markdown-body h1 .octicon-link,.markdown-body h2 .octicon-link,.markdown-body h3 .octicon-link,.markdown-body h4 .octicon-link,.markdown-body h5 .octicon-link,.markdown-body h6 .octicon-link{color:#000;vertical-align:middle;visibility:hidden}.markdown-body h1:hover .anchor,.markdown-body h2:hover .anchor,.markdown-body h3:hover .anchor,.markdown-body h4:hover .anchor,.markdown-body h5:hover .anchor,.markdown-body h6:hover .anchor{text-decoration:none}.markdown-body h1:hover .anchor .octicon-link,.markdown-body h2:hover .anchor .octicon-link,.markdown-body h3:hover .anchor .octicon-link,.markdown-body h4:hover .anchor .octicon-link,.markdown-body h5:hover .anchor .octicon-link,.markdown-body h6:hover .anchor .octicon-link{visibility:visible}.markdown-body h1 code,.markdown-body h1 tt,.markdown-body h2 code,.markdown-body h2 tt,.markdown-body h3 code,.markdown-body h3 tt,.markdown-body h4 code,.markdown-body h4 tt,.markdown-body h5 code,.markdown-body h5 tt,.markdown-body h6 code,.markdown-body h6 tt{font-size:inherit}.markdown-body h1{font-size:2em}.markdown-body h1,.markdown-body h2{padding-bottom:.3em;border-bottom:1px solid #eee}.markdown-body h2{font-size:1.5em}.markdown-body h3{font-size:1.25em}.markdown-body h4{font-size:1em}.markdown-body h5{font-size:.875em}.markdown-body h6{font-size:.85em;color:#777}.markdown-body ol,.markdown-body ul{padding-left:2em}.markdown-body ol.no-list,.markdown-body ul.no-list{padding:0;list-style-type:none}.markdown-body ol ol,.markdown-body ol ul,.markdown-body ul ol,.markdown-body ul ul{margin-top:0;margin-bottom:0}.markdown-body li>p{margin-top:16px}.markdown-body li+li{padding-top:.25em}.markdown-body dl{padding:0}.markdown-body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}.markdown-body dl dd{padding:0 16px;margin-bottom:16px}.markdown-body table{display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}.markdown-body table th{font-weight:700}.markdown-body table td,.markdown-body table th{padding:6px 13px;border:1px solid #ddd}.markdown-body table tr{background-color:#fff;border-top:1px solid #ccc}.markdown-body table tr:nth-child(2n){background-color:#f8f8f8}.markdown-body img{max-width:100%;box-sizing:content-box;background-color:#fff}.markdown-body img[align=right]{padding-left:20px}.markdown-body img[align=left]{padding-right:20px}.markdown-body .emoji{max-width:none;vertical-align:text-top;background-color:transparent}.markdown-body span.frame{display:block;overflow:hidden}.markdown-body span.frame>span{display:block;float:left;width:auto;padding:7px;margin:13px 0 0;overflow:hidden;border:1px solid #ddd}.markdown-body span.frame span img{display:block;float:left}.markdown-body span.frame span span{display:block;padding:5px 0 0;clear:both;color:#333}.markdown-body span.align-center{display:block;overflow:hidden;clear:both}.markdown-body span.align-center>span{display:block;margin:13px auto 0;overflow:hidden;text-align:center}.markdown-body span.align-center span img{margin:0 auto;text-align:center}.markdown-body span.align-right{display:block;overflow:hidden;clear:both}.markdown-body span.align-right>span{display:block;margin:13px 0 0;overflow:hidden;text-align:right}.markdown-body span.align-right span img{margin:0;text-align:right}.markdown-body span.float-left{display:block;float:left;margin-right:13px;overflow:hidden}.markdown-body span.float-left span{margin:13px 0 0}.markdown-body span.float-right{display:block;float:right;margin-left:13px;overflow:hidden}.markdown-body span.float-right>span{display:block;margin:13px auto 0;overflow:hidden;text-align:right}.markdown-body code,.markdown-body tt{padding:0;padding-top:.2em;padding-bottom:.2em;margin:0;font-size:85%;background-color:rgba(0,0,0,.04);border-radius:3px}.markdown-body code:after,.markdown-body code:before,.markdown-body tt:after,.markdown-body tt:before{letter-spacing:-.2em;content:"\00a0"}.markdown-body code br,.markdown-body tt br{display:none}.markdown-body del code{text-decoration:inherit}.markdown-body pre{word-wrap:normal}.markdown-body pre>code{padding:0;margin:0;font-size:100%;word-break:normal;white-space:pre;background:transparent;border:0}.markdown-body .highlight{margin-bottom:16px}.markdown-body .highlight pre{margin-bottom:0;word-break:normal}.markdown-body .highlight pre,.markdown-body pre{padding:16px;overflow:auto;font-size:85%;line-height:1.45;background-color:#f7f7f7;border-radius:3px}.markdown-body pre code,.markdown-body pre tt{display:inline;max-width:auto;padding:0;margin:0;overflow:visible;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}.markdown-body pre code:after,.markdown-body pre code:before,.markdown-body pre tt:after,.markdown-body pre tt:before{content:normal}.markdown-body .csv-data td,.markdown-body .csv-data th{padding:5px;overflow:hidden;font-size:12px;line-height:1;text-align:left;white-space:nowrap}.markdown-body .csv-data .blob-line-num{padding:10px 8px 9px;text-align:right;background:#fff;border:0}.markdown-body .csv-data tr{border-top:0}.markdown-body .csv-data th{font-weight:700;background:#f8f8f8;border-top:0}.news .alert .markdown-body blockquote{padding:0 0 0 40px;border:0 none}.activity-tab .news .alert .commits,.activity-tab .news .markdown-body blockquote{padding-left:0}.task-list-item{list-style-type:none}.task-list-item label{font-weight:400}.task-list-item.enabled label{cursor:pointer}.task-list-item+.task-list-item{margin-top:3px}.task-list-item-checkbox{float:left;margin:.31em 0 .2em -1.3em!important;vertical-align:middle;cursor:default!important}.markdown-body{padding-top:40px;padding-bottom:40px;max-width:758px;overflow:visible!important;position:relative}.markdown-body .emoji{vertical-align:top}.markdown-body pre{border:inherit!important}.markdown-body code{color:inherit!important}.markdown-body pre code .wrapper{display:-moz-inline-flex;display:-ms-inline-flex;display:-o-inline-flex;display:inline-flex}.markdown-body pre code .gutter{float:left;overflow:hidden;-webkit-user-select:none;user-select:none}.markdown-body pre code .gutter.linenumber{text-align:right;position:relative;display:inline-block;cursor:default;z-index:4;padding:0 8px 0 0;min-width:20px;box-sizing:content-box;color:#afafaf!important;border-right:3px solid #6ce26c!important}.markdown-body pre code .gutter.linenumber>span:before{content:attr(data-linenumber)}.markdown-body pre code .code{float:left;margin:0 0 0 16px}.markdown-body .gist .line-numbers{border-left:none;border-top:none;border-bottom:none}.markdown-body .gist .line-data{border:none}.markdown-body .gist table{border-spacing:0;border-collapse:inherit!important}.markdown-body code[data-gist-id]{background:none;padding:0}.markdown-body code[data-gist-id]:after,.markdown-body code[data-gist-id]:before{content:""}.markdown-body code[data-gist-id] .blob-num{border:unset}.markdown-body code[data-gist-id] table{overflow:unset;margin-bottom:unset}.markdown-body code[data-gist-id] table tr{background:unset}.markdown-body[dir=rtl] pre{direction:ltr}.markdown-body[dir=rtl] code{direction:ltr;unicode-bidi:embed}.markdown-body .alert>p:last-child{margin-bottom:0}.markdown-body pre.abc,.markdown-body pre.flow-chart,.markdown-body pre.graphviz,.markdown-body pre.mermaid,.markdown-body pre.sequence-diagram,.markdown-body pre.vega{text-align:center;background-color:inherit;border-radius:0;white-space:inherit;overflow:visible}.markdown-body pre.abc>code,.markdown-body pre.flow-chart>code,.markdown-body pre.graphviz>code,.markdown-body pre.mermaid>code,.markdown-body pre.sequence-diagram>code,.markdown-body pre.vega>code{text-align:left}.markdown-body pre.abc>svg,.markdown-body pre.flow-chart>svg,.markdown-body pre.graphviz>svg,.markdown-body pre.mermaid>svg,.markdown-body pre.sequence-diagram>svg,.markdown-body pre.vega>svg{max-width:100%;height:100%}.markdown-body pre>code.wrap{white-space:pre-wrap;white-space:-moz-pre-wrap;white-space:-pre-wrap;white-space:-o-pre-wrap;word-wrap:break-word}.markdown-body .alert>p:last-child,.markdown-body .alert>ul:last-child{margin-bottom:0}.markdown-body summary{display:list-item}.markdown-body summary:focus{outline:none}.markdown-body details summary{cursor:pointer}.markdown-body details:not([open])>:not(summary){display:none}.markdown-body figure{margin:1em 40px}.markdown-body .mark,.markdown-body mark{background-color:#fff1a7}.vimeo,.youtube{cursor:pointer;display:table;text-align:center;background-position:50%;background-repeat:no-repeat;background-size:contain;background-color:#000;overflow:hidden}.vimeo,.youtube{position:relative;width:100%}.youtube{padding-bottom:56.25%}.vimeo img{width:100%;object-fit:contain;z-index:0}.youtube img{object-fit:cover;z-index:0}.vimeo iframe,.youtube iframe,.youtube img{width:100%;height:100%;position:absolute;top:0;left:0}.vimeo iframe,.youtube iframe{vertical-align:middle;z-index:1}.vimeo .icon,.youtube .icon{position:absolute;height:auto;width:auto;top:50%;left:50%;transform:translate(-50%,-50%);color:#fff;opacity:.3;transition:opacity .2s;z-index:0}.vimeo:hover .icon,.youtube:hover .icon{opacity:.6;transition:opacity .2s}.slideshare .inner,.speakerdeck .inner{position:relative;width:100%}.slideshare .inner iframe,.speakerdeck .inner iframe{position:absolute;top:0;bottom:0;left:0;right:0;width:100%;height:100%}.figma{display:table;position:relative;width:100%;padding-bottom:56.25%}.figma iframe{position:absolute;top:0;bottom:0;left:0;right:0;width:100%;height:100%;border:1px solid #eee}.markmap-container{height:300px}.markmap-container>svg{width:100%;height:100%}.MJX_Assistive_MathML{display:none}#MathJax_Message{z-index:1000!important}.ui-infobar{position:relative;z-index:2;max-width:760px;margin:25px auto -25px;color:#777}.toc .invisable-node{list-style-type:none}.ui-toc{position:fixed;bottom:20px;z-index:998}.ui-toc.both-mode{margin-left:8px}.ui-toc.both-mode .ui-toc-label{height:40px;padding:10px 4px;border-top-left-radius:0;border-bottom-left-radius:0}.ui-toc-label{background-color:#e6e6e6;border:none;color:#868686;transition:opacity .2s}.ui-toc .open .ui-toc-label{opacity:1;color:#fff;transition:opacity .2s}.ui-toc-label:focus{opacity:.3;background-color:#ccc;color:#000}.ui-toc-label:hover{opacity:1;background-color:#ccc;transition:opacity .2s}.ui-toc-dropdown{margin-top:20px;margin-bottom:20px;padding-left:10px;padding-right:10px;max-width:45vw;width:25vw;max-height:70vh;overflow:auto;text-align:inherit}.ui-toc-dropdown>.toc{max-height:calc(70vh - 100px);overflow:auto}.ui-toc-dropdown[dir=rtl] .nav{padding-right:0;letter-spacing:.0029em}.ui-toc-dropdown a{overflow:hidden;text-overflow:ellipsis;white-space:pre}.ui-toc-dropdown .nav>li>a{display:block;padding:4px 20px;font-size:13px;font-weight:500;color:#767676}.ui-toc-dropdown .nav>li:first-child:last-child>ul,.ui-toc-dropdown .toc.expand ul{display:block}.ui-toc-dropdown .nav>li>a:focus,.ui-toc-dropdown .nav>li>a:hover{padding-left:19px;color:#000;text-decoration:none;background-color:transparent;border-left:1px solid #000}.ui-toc-dropdown[dir=rtl] .nav>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav>li>a:hover{padding-right:19px;border-left:none;border-right:1px solid #000}.ui-toc-dropdown .nav>.active:focus>a,.ui-toc-dropdown .nav>.active:hover>a,.ui-toc-dropdown .nav>.active>a{padding-left:18px;font-weight:700;color:#000;background-color:transparent;border-left:2px solid #000}.ui-toc-dropdown[dir=rtl] .nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav>.active>a{padding-right:18px;border-left:none;border-right:2px solid #000}.ui-toc-dropdown .nav .nav{display:none;padding-bottom:10px}.ui-toc-dropdown .nav>.active>ul{display:block}.ui-toc-dropdown .nav .nav>li>a{padding-top:1px;padding-bottom:1px;padding-left:30px;font-size:12px;font-weight:400}.ui-toc-dropdown[dir=rtl] .nav .nav>li>a{padding-right:30px}.ui-toc-dropdown .nav .nav>li>ul>li>a{padding-top:1px;padding-bottom:1px;padding-left:40px;font-size:12px;font-weight:400}.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a{padding-right:40px}.ui-toc-dropdown .nav .nav>li>a:focus,.ui-toc-dropdown .nav .nav>li>a:hover{padding-left:29px}.ui-toc-dropdown[dir=rtl] .nav .nav>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav .nav>li>a:hover{padding-right:29px}.ui-toc-dropdown .nav .nav>li>ul>li>a:focus,.ui-toc-dropdown .nav .nav>li>ul>li>a:hover{padding-left:39px}.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a:hover{padding-right:39px}.ui-toc-dropdown .nav .nav>.active:focus>a,.ui-toc-dropdown .nav .nav>.active:hover>a,.ui-toc-dropdown .nav .nav>.active>a{padding-left:28px;font-weight:500}.ui-toc-dropdown[dir=rtl] .nav .nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>a{padding-right:28px}.ui-toc-dropdown .nav .nav>.active>.nav>.active:focus>a,.ui-toc-dropdown .nav .nav>.active>.nav>.active:hover>a,.ui-toc-dropdown .nav .nav>.active>.nav>.active>a{padding-left:38px;font-weight:500}.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active>a{padding-right:38px}.markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,sans-serif}html[lang^=ja] .markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}html[lang=zh-tw] .markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}html[lang=zh-cn] .markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}html .markdown-body[lang^=ja]{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}html .markdown-body[lang=zh-tw]{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}html .markdown-body[lang=zh-cn]{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}html[lang^=ja] .ui-toc-dropdown{font-family:Source Sans Pro,Helvetica,Arial,Meiryo UI,MS PGothic,ＭＳ\ Ｐゴシック,sans-serif}html[lang=zh-tw] .ui-toc-dropdown{font-family:Source Sans Pro,Helvetica,Arial,Microsoft JhengHei UI,微軟正黑UI,sans-serif}html[lang=zh-cn] .ui-toc-dropdown{font-family:Source Sans Pro,Helvetica,Arial,Microsoft YaHei UI,微软雅黑UI,sans-serif}html .ui-toc-dropdown[lang^=ja]{font-family:Source Sans Pro,Helvetica,Arial,Meiryo UI,MS PGothic,ＭＳ\ Ｐゴシック,sans-serif}html .ui-toc-dropdown[lang=zh-tw]{font-family:Source Sans Pro,Helvetica,Arial,Microsoft JhengHei UI,微軟正黑UI,sans-serif}html .ui-toc-dropdown[lang=zh-cn]{font-family:Source Sans Pro,Helvetica,Arial,Microsoft YaHei UI,微软雅黑UI,sans-serif}.ui-affix-toc{position:fixed;top:0;max-width:15vw;max-height:70vh;overflow:auto}.back-to-top,.expand-toggle,.go-to-bottom{display:block;padding:4px 10px;margin-top:10px;margin-left:10px;font-size:12px;font-weight:500;color:#999}.back-to-top:focus,.back-to-top:hover,.expand-toggle:focus,.expand-toggle:hover,.go-to-bottom:focus,.go-to-bottom:hover{color:#563d7c;text-decoration:none}.back-to-top,.go-to-bottom{margin-top:0}.ui-user-icon{width:20px;height:20px;display:block;border-radius:50%;margin-top:2px;margin-bottom:2px;margin-right:5px;background-position:50%;background-repeat:no-repeat;background-size:cover}.ui-user-icon.small{width:18px;height:18px;display:inline-block;vertical-align:middle;margin:0 0 .2em}.ui-infobar>small>span{line-height:22px}.ui-infobar>small .dropdown{display:inline-block}.ui-infobar>small .dropdown a:focus,.ui-infobar>small .dropdown a:hover{text-decoration:none}.ui-more-info{color:#888;cursor:pointer;vertical-align:middle}.ui-more-info .fa{font-size:16px}.ui-connectedGithub,.ui-published-note{color:#888}.ui-connectedGithub{line-height:23px;white-space:nowrap}.ui-connectedGithub a.file-path{color:#888;text-decoration:none;padding-left:22px}.ui-connectedGithub a.file-path:active,.ui-connectedGithub a.file-path:hover{color:#888;text-decoration:underline}.ui-connectedGithub .fa{font-size:20px}.ui-published-note .fa{font-size:20px;vertical-align:top}.unselectable{-webkit-user-select:none;-o-user-select:none;user-select:none}.selectable{-webkit-user-select:text;-o-user-select:text;user-select:text}.inline-spoiler-section{cursor:pointer}.inline-spoiler-section .spoiler-text{border-radius:2px;background-color:#333}.inline-spoiler-section .spoiler-text>*{opacity:0}.inline-spoiler-section .spoiler-img{filter:blur(10px)}.inline-spoiler-section.raw{border-radius:2px;background-color:#333}.inline-spoiler-section.raw>*{opacity:0}.inline-spoiler-section.unveil{cursor:auto}.inline-spoiler-section.unveil .spoiler-text{background-color:rgba(51,51,51,.1)}.inline-spoiler-section.unveil .spoiler-text>*{opacity:1}.inline-spoiler-section.unveil .spoiler-img{filter:none}@media print{blockquote,div,img,pre,table{page-break-inside:avoid!important}a[href]:after{font-size:12px!important}}.markdown-body.slides{position:relative;z-index:1;color:#222}.markdown-body.slides:before{content:"";display:block;position:absolute;top:0;left:0;right:0;bottom:0;z-index:-1;background-color:currentColor;box-shadow:0 0 0 50vw}.markdown-body.slides section[data-markdown]{position:relative;margin-bottom:1.5em;background-color:#fff;text-align:center}.markdown-body.slides section[data-markdown] code{text-align:left}.markdown-body.slides section[data-markdown]:before{content:"";display:block;padding-bottom:56.23%}.markdown-body.slides section[data-markdown]>div:first-child{position:absolute;top:50%;left:1em;right:1em;transform:translateY(-50%);max-height:100%;overflow:hidden}.markdown-body.slides section[data-markdown]>ul{display:inline-block}.markdown-body.slides>section>section+section:after{content:"";position:absolute;top:-1.5em;right:1em;height:1.5em;border:3px solid #777}.site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,sans-serif}html[lang^=ja] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}html[lang=zh-tw] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}html[lang=zh-cn] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}body{font-smoothing:subpixel-antialiased!important;-webkit-font-smoothing:subpixel-antialiased!important;-moz-osx-font-smoothing:auto!important;text-shadow:0 0 1em transparent,1px 1px 1.2px rgba(0,0,0,.004);-webkit-overflow-scrolling:touch;letter-spacing:.025em;font-family:Source Sans Pro,Helvetica,Arial,sans-serif}html[lang^=ja] body{font-family:Source Sans Pro,Helvetica,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}html[lang=zh-tw] body{font-family:Source Sans Pro,Helvetica,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}html[lang=zh-cn] body{font-family:Source Sans Pro,Helvetica,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}abbr[data-original-title],abbr[title]{cursor:help}body.modal-open{overflow-y:auto;padding-right:0!important}
    </style>
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    	<script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" integrity="sha256-3Jy/GbSLrg0o9y5Z5n1uw0qxZECH7C6OQpVBgNFYa0g=" crossorigin="anonymous"></script>
    	<script src="https://cdnjs.cloudflare.com/ajax/libs/respond.js/1.4.2/respond.min.js" integrity="sha256-g6iAfvZp+nDQ2TdTR/VVKJf3bGro4ub5fvWSWVRi2NE=" crossorigin="anonymous"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js" integrity="sha256-8E4Is26QH0bD52WoQpcB+R/tcWQtpzlCojrybUd7Mxo=" crossorigin="anonymous"></script>
    <![endif]-->
</head>

<body>
    <div id="doc" class="markdown-body container-fluid comment-enabled" data-hard-breaks="true"><h1 id="184702-Machine-Learning---Exercise-3-Report" data-id="184702-Machine-Learning---Exercise-3-Report"><a class="anchor hidden-xs" href="#184702-Machine-Learning---Exercise-3-Report" title="184702-Machine-Learning---Exercise-3-Report"><span class="octicon octicon-link"></span></a><span>184.702 Machine Learning - Exercise 3 Report</span></h1><h2 id="Deep-Learning---Text-Classification" data-id="Deep-Learning---Text-Classification"><a class="anchor hidden-xs" href="#Deep-Learning---Text-Classification" title="Deep-Learning---Text-Classification"><span class="octicon octicon-link"></span></a><span>Deep Learning - Text Classification</span></h2><p><em><span>Chakarov Teodor, Hollaus Aymeric, Moulinier Arthur</span></em></p><hr><h1 id="Introduction" data-id="Introduction"><a class="anchor hidden-xs" href="#Introduction" title="Introduction"><span class="octicon octicon-link"></span></a><span>Introduction</span></h1><p><span>For the final exercise we opted for </span><strong><span>Topic 3.2.1: Text classification - Feature Extraction &amp; Shallow vs. Deep Learning</span></strong><span>. The main goal of this exercise was to understand the importance of representation &amp; extraction of information from text. First we had to pick a good classifier with standard feature extraction methods, be it either </span><em><span>Bag Of Words</span></em><span>, </span><em><span>n-grams</span></em><span> or others.</span><br>
<span>We used Bag of Words (Count Vectorizer and </span><em><span>Tfidf</span></em><span>-Vectorizer) approach for vectorizing the text. We need to transform the unstructured data in some form of numeric vector representations. Alongside that, we picked two data sets, they will be quickly introduced in the </span><strong><span>Data</span></strong><span> section. Then we analyzed it on several algorithms with different parameter settings to see the overall performance. Secondly, we compared basic Machine learning approaches and we compared them with neural networks. We looked at the “basic” </span><em><span>RNN</span></em><span> approach, a </span><em><span>RNN</span></em><span> approach with a </span><em><span>BiDirectional LSTM</span></em><span> layer. We also looked at </span><em><span>DistilBert</span></em><span> (Bi-decertional transformer). </span><em><span>BERT</span></em><span> is state of the art transformer model for extracting meaningfull word embeddings. With the Multi-layer self-attention, it keeps information for evry word in the context of the sentance, not only words before and after. This section just serves the purpose to give a general overview of the exercise. All of these steps will be explained properly in the up-coming sections, including graphs and images.</span></p><h1 id="Data" data-id="Data"><a class="anchor hidden-xs" href="#Data" title="Data"><span class="octicon octicon-link"></span></a><span>Data</span></h1><h2 id="Data-1-News-Classification" data-id="Data-1-News-Classification"><a class="anchor hidden-xs" href="#Data-1-News-Classification" title="Data-1-News-Classification"><span class="octicon octicon-link"></span></a><span>Data 1: News Classification</span></h2><p><span>Our first dataset is pulled from </span><em><span>Kaggle</span></em><span>, which can be found </span><a href="https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset?select=train.csv%22" target="_blank" rel="noopener"><span>here</span></a><span>. It is a collection of news articles belonging to the domains of “world”, “sports”, “business” and “science”. These classes were split proportionally within the sets. It is a fairly large collection of more than one million news articles from about 2,000 different news sources. These articles have been pulled from </span><em><span>ComeToMyHead</span></em><span> which is an academic news search engine and the time span was about a year or so.</span></p><h2 id="Data-2-Twitter-Data-classification" data-id="Data-2-Twitter-Data-classification"><a class="anchor hidden-xs" href="#Data-2-Twitter-Data-classification" title="Data-2-Twitter-Data-classification"><span class="octicon octicon-link"></span></a><span>Data 2: Twitter Data classification</span></h2><p><span>For the second one we opted for a different set of text data, specifically tweets from </span><em><span>Twitter</span></em><span>. Again pulled from </span><em><span>Kaggle</span></em><span>, </span><a href="https://www.kaggle.com/code/arunrk7/nlp-beginner-text-classification-using-lstm/data" target="_blank" rel="noopener"><span>here</span></a><span>, this dataset contains 1,600,000 tweets extracted through the </span><strong><span>Twitter API</span></strong><span>. The tweets have been annotated (0 = negative and 4 = positive) and represent sentiment by categorizing the popularity of the tweet. You will notice that on in our files the </span><em><span>.csv</span></em><span> is different, and that is because we create a smaller version of the same data (to avoid long epochs, etc.).</span></p><h1 data-id="Our-Approach" id="Our-Approach"><a class="anchor hidden-xs" href="#Our-Approach" title="Our-Approach"><span class="octicon octicon-link"></span></a><span>Our Approach</span></h1><p><span>This section will explain step-by-step our implementation, whereas the </span><strong><span>Discussion</span></strong><span> section will discuss the findings and hopefully describe the differences between the traditional and deep learning techniques properly.</span></p><h2 id="Step-1-Defining-our-Text-Classification" data-id="Step-1-Defining-our-Text-Classification"><a class="anchor hidden-xs" href="#Step-1-Defining-our-Text-Classification" title="Step-1-Defining-our-Text-Classification"><span class="octicon octicon-link"></span></a><span>Step 1: Defining our Text Classification</span></h2><p><span>First we import all needed libraries which are (but not exclusively) </span><em><span>tensorflow</span></em><span>, </span><em><span>sklearn</span></em><span>, </span><em><span>ntlk</span></em><span>, </span><em><span>matplotlib</span></em><span>, </span><em><span>seaborn</span></em><span>, </span><em><span>numpy</span></em><span>, </span><em><span>pandas</span></em><span> and others. We create a variable named </span><code>gpus</code><span>, which as the name implies represent our actual </span><em><span>GPU</span></em><span>. Using </span><em><span>tensorflow</span></em><span> functions recognizing our </span><em><span>GPUs</span></em><span> is fairly easy as well as configuring them. This will facilitate our workflow and utilizing </span><em><span>GPU</span></em><span> processing power will definitely decrease the execution time of our models (in Neural Networks </span><em><span>GPUs</span></em><span> are pretty much a must-have; maybe very small scales </span><em><span>NNs</span></em><span> can make do without one).</span><br>
<span>Before utilizing and implementing our models and algorithms, we have to define our functions to get the model scores, neural network scores and overall scores. For scoring we used the “usual candidates”: </span><em><span>Accuracy</span></em><span>, </span><em><span>F1 Score</span></em><span>, </span><em><span>Precision</span></em><span>, </span><em><span>Recall</span></em><span> and </span><em><span>ROC_AUC</span></em><span>. We will not describe them further since we already did so in our past exercises. Parallel to this, we also import some stopwords from the natural language toolkit library, </span><em><span>ntlk</span></em><span>. Additionally we defined some constants such as vocabulary size, embedding dimensions. We weren’t quite sure if these values should be accepted as an input as well or not.</span></p><blockquote>
<p><span>Note: We used the random seed 24.</span><br>
<span>Interesting note: As powerful as </span><em><span>NNs</span></em><span> are they are sadly very energy inefficient and will need to be improved for further usage in the future. See </span><a href="https://www.sciencedirect.com/science/article/pii/S0743731518308773" target="_blank" rel="noopener"><span>this paper</span></a><span>.</span></p>
</blockquote><h2 id="Step-2-Import-Analyze-and-Preprocess-the-Data" data-id="Step-2-Import-Analyze-and-Preprocess-the-Data"><a class="anchor hidden-xs" href="#Step-2-Import-Analyze-and-Preprocess-the-Data" title="Step-2-Import-Analyze-and-Preprocess-the-Data"><span class="octicon octicon-link"></span></a><span>Step 2: Import, Analyze and Preprocess the Data</span></h2><h3 id="News-Classification" data-id="News-Classification"><a class="anchor hidden-xs" href="#News-Classification" title="News-Classification"><span class="octicon octicon-link"></span></a><span>News Classification</span></h3><h4 id="Split-data" data-id="Split-data"><a class="anchor hidden-xs" href="#Split-data" title="Split-data"><span class="octicon octicon-link"></span></a><span>Split data</span></h4><p><span>The total split of this data is about 96,000 training samples and 19,600 validation samples and 12,000 test samples. Lastly, the labels are equally distributed, as can be seen below.</span></p><p><img src="https://i.imgur.com/mc8SE3x.png" alt="" loading="lazy"></p><h4 id="Text-Pre-Processing" data-id="Text-Pre-Processing"><a class="anchor hidden-xs" href="#Text-Pre-Processing" title="Text-Pre-Processing"><span class="octicon octicon-link"></span></a><span>Text Pre-Processing</span></h4><p><span>First we label encoded the classes, from 0 to 3. Afterwards we applied text tokenization (tokenization is a way of separating a piece of text into smaller units called tokens) and vectorization (text vectorization is the process of converting text into numerical representation), where we used 8000 words to be stored in the vocabulary (The most common ones). The </span><em><span>CountVectorizer</span></em><span> was used, which tokenizes, removes the stop words and applies lower casing for the tokens. For </span><em><span>n-gram</span></em><span> we used the (1,1) one, meaning our bag of words can only include unigrams. Please note that we did all of this after splitting the data, since we didn’t do so in previous exercises and it was bad practice/impacted our data incorrectly. We used the given method for the basic machine learning algorithms. For the neural networks we used the tokenizer, provided by the </span><em><span>Keras API</span></em><span>. It also is needed to add padding to the sentences, because they are working with symmetrical dimensions of data (</span><a href="https://medium.com/@canerkilinc/padding-for-nlp-7dd8598c916a" target="_blank" rel="noopener"><span>this</span></a><span> </span><em><span>Medium</span></em><span> article talks about it and is fairly insightful). Based on the density of text length for each document which you can see:</span></p><p><img src="https://i.imgur.com/CNnKcXq.png" alt="" loading="lazy"></p><p><span>We are using 40 tokens for each observation. That means that sentences less than 40, will have zero’s in the end, and sentences with more than 40 will be trimmed. Here is an example for tokenized sentences which has less than 40 tokens:</span></p><p><img src="https://i.imgur.com/tiXghJN.png" alt="" loading="lazy"></p><p><span>For the </span><em><span>BERT</span></em><span> model (which we will explain in the upcoming </span><strong><span>Models</span></strong><span> Section) we have to use a different kind of tokenization. We used a pre-trained word dictionary, which was available from the </span><em><strong><span>transformers API</span></strong></em><span>. To be specific, we used a “smaller” version of the </span><em><span>BERT</span></em><span> model, which is </span><em><span>DistlBERT</span></em><span>. After we applied the tokenization, the following 3 kinds of arrays can be seen:</span></p><p><img src="https://i.imgur.com/ExA6lAM.png" alt="" loading="lazy"></p><p><span>Every model is different yet shares similarities with the others. Therefore most models use the similar input aspects, which are mainly the three following:</span></p><ol>
<li><strong><span>Input IDs</span></strong><span>: The </span><em><span>input ids</span></em><span> are often the only required parameters to be passed to the model as input. For classification problems, two inputs sentences should be tokenized and concatenated together. We can see a lot of </span><strong><span>101</span></strong><span> start ids and at the end often </span><strong><span>102</span></strong><span>. Those are special BERT tokens, </span><em><span>CLS</span></em><span> (classification) and </span><em><span>SEP</span></em><span> (necessary for Next Sentence Prediction) tokens to be exact.</span></li>
<li><strong><span>Input masks</span></strong><span>: Also called attention mask, it basically is an optional “argument” used for batching sequences. It allows the model to cleanly differentiate between the content and the padding. The mask has the same shape as the </span><em><span>input ids</span></em><span>, and contains 1 wherever the </span><em><span>input ids</span></em><span> have no padding.</span></li>
<li><strong><span>Input types</span></strong><span>: Also called token type ids, they are mainly used on pairs of sequences or question answering. In has the same shape as the </span><em><span>input ids</span></em><span>, but inside the non-padded region, it contains 0 or 1 indicating which sentence the token is a part of.</span></li>
</ol><p><span>For our </span><em><span>BERT</span></em><span> model we used only the </span><em><span>Input IDs</span></em><span> and the </span><em><span>Input masks</span></em><span>.</span></p><h3 id="Twitter-Data-Classification" data-id="Twitter-Data-Classification"><a class="anchor hidden-xs" href="#Twitter-Data-Classification" title="Twitter-Data-Classification"><span class="octicon octicon-link"></span></a><span>Twitter Data Classification</span></h3><h4 id="Split-data1" data-id="Split-data"><a class="anchor hidden-xs" href="#Split-data1" title="Split-data1"><span class="octicon octicon-link"></span></a><span>Split data</span></h4><p><span>We will not go into much detail here since we applied the same concepts as above.</span></p><p><img src="https://i.imgur.com/cdX9juu.png" alt="" loading="lazy"></p><p><span>About 60,088 Positive (test and validation) and Negative 59,912 (test and validation). Please not that we changed the labels to “Satisfied” and “Not Satisfied” (1 and 0 accordingly).</span></p><h4 id="Text-Pre-Processing1" data-id="Text-Pre-Processing"><a class="anchor hidden-xs" href="#Text-Pre-Processing1" title="Text-Pre-Processing1"><span class="octicon octicon-link"></span></a><span>Text Pre-Processing</span></h4><p><span>We used the CountVectorizer and Tokenizer for the Neural Networks. For the pre-processing we used Same graphic as above but including validation data as well, just to offer more insights. We see the distribution of the lengths for each document. We are going to use the padding=10.</span></p><p><img src="https://i.imgur.com/1be7mq2.png" alt="" loading="lazy"></p><h2 id="Step-3-Models" data-id="Step-3-Models"><a class="anchor hidden-xs" href="#Step-3-Models" title="Step-3-Models"><span class="octicon octicon-link"></span></a><span>Step 3: Models</span></h2><p><span>We fitted the data into </span><em><span>Random forest</span></em><span>, </span><em><span>Decision tree</span></em><span> and </span><em><span>Logisic regression</span></em><span>, just to evaluate which algorithm performed better than the others. After that we applied </span><em><span>Gridsearch</span></em><span>, with cross-validation, in an attempt to find the best hyper-parameters, which would help us to avoid over-fitting. The following measures are performed on </span><em><strong><span>train data</span></strong></em><span> and </span><em><strong><span>validation data</span></strong></em><span>. The inference time measures how long it takes for the model to output the predictions.</span></p><p><span>We wanted to save some space so the models are not describe in-depth here but more info can be found on our notebook.</span></p><p><span>For Neural Networks we need also to configure the last layer, since we have binary classification and multi label classification. For multi-label we use as activation function “softmax” and for binary we use “sigmoid”. Also we changed the loss functions. For multi-label classification we used “SparseCategoricalCrossentropy” and for binary - “binary crossentropy”.</span></p><h2 id="News-Classification1" data-id="News-Classification"><a class="anchor hidden-xs" href="#News-Classification1" title="News-Classification1"><span class="octicon octicon-link"></span></a><span>News Classification</span></h2><p><strong><span>Best Machine Learning Algorithm</span></strong><span> was </span><em><span>Logistic Regression</span></em><span> and after </span><em><span>Grid Search</span></em><span> with the hyper-parameter </span><em><span>C=1</span></em><span> we achieved the given score:</span></p><p><img src="https://i.imgur.com/UmCwfzZ.png" alt="" loading="lazy"></p><p><span>Training time: 57.55 seconds.</span><br>
<span>Our </span><strong><span>simple RNN</span></strong><span> model managed to achieve:</span></p><p><img src="https://i.imgur.com/LlYPPtO.png" alt="" loading="lazy"></p><p><span>It achieved almost the same results as the </span><em><span>Logistic Regression</span></em><span>. But the difference lies in the inference time. Training time: 87.62 seconds.</span><br>
<span>Our </span><strong><span>Bi-Directional LSTM</span></strong><span> model also achieved same results:</span></p><p><img src="https://i.imgur.com/9YIgUkS.png" alt="" loading="lazy"></p><p><span>For our </span><strong><span>DistilBERT</span></strong><span> model, we froze the paramethers to me non-trainable because it is giving us better text representations (since its ppre-trained), which we fit to our small Neural Network with 2 Dense layers. We let the small model to be trainable. The results are better than the previous algorithms:</span></p><p><img src="https://i.imgur.com/eoOXzRx.png" alt="" loading="lazy"></p><h2 id="Twitter-Sentiment-Classification" data-id="Twitter-Sentiment-Classification"><a class="anchor hidden-xs" href="#Twitter-Sentiment-Classification" title="Twitter-Sentiment-Classification"><span class="octicon octicon-link"></span></a><span>Twitter Sentiment Classification</span></h2><p><span>Again to avoid repetition not much will be added here besides the results. One should note that the inference time will be faster not only due to it being a reduced size dataset but mainly because of it being a bi-label dataset compared to the prior multi-label one.</span></p><p><strong><span>Best Machine Learning Algorithm</span></strong><span> (</span><em><span>LogisticRegression</span></em><span>, C=0.1):</span></p><p><img src="https://i.imgur.com/oc4f0cQ.png" alt="" loading="lazy"></p><p><span>We assumed that </span><em><span>Logistic Regression</span></em><span> would perform slightly better here compared to the previous dataset due to it’s nature, meaning its bi-label aspect. </span><em><span>Logistic Regression</span></em><span>, as already mentioned, is a sigmoid function (S-Shaped curve) and these functions perform better with data that can be predicted between 0 and 1. We were surprised that this wasn’t the case, but this again could simply be due to the fact that classifying such data is tougher than news.</span><br>
<strong><span>Simple RNN</span></strong><span>:</span></p><p><img src="https://i.imgur.com/cljMnP0.png" alt="" loading="lazy"></p><p><strong><span>Bi-Directional LSTM</span></strong><span>:</span></p><p><img src="https://i.imgur.com/I0tmcIS.png" alt="" loading="lazy"></p><p><span>Surprisingly this performed slightly worse than </span><em><span>Simple RNN</span></em><span>.</span><br>
<strong><span>DistilBERT</span></strong><span>:</span><br>
<em><span>Sadly our table got lost on Imgur and recreating it this late is not doable. Please direct yourselves to the notebook where it can be seen/executed.</span></em></p><h1 id="How-To" data-id="How-To"><a class="anchor hidden-xs" href="#How-To" title="How-To"><span class="octicon octicon-link"></span></a><span>How-To</span></h1><p><span>Here we had some uncertainties due to the wording </span><em><span>programmatically</span></em><span>. We are using Python in a </span><em><span>Jupyter Notebook</span></em><span> environment, meaning it is indeed programmatically done but it also is interactive and includes a </span><em><span>GUI</span></em><span>. We decided to keep it this way and hope this isn’t causing any issues. Otherwise we would have simply modified the notebook into a Python script, added a </span><em><span>requirements.txt</span></em><span> file and lastly created a script (i.e. bash) that executes </span><code>pip install -r requirements.txt</code><span>, our script and accepts environment variables. We did create a </span><em><span>requirements.txt</span></em><span> with </span><strong><span>pipreqsnb</span></strong><span> (</span><strong><span>pipreqs</span></strong><span> wrapper for notebook) and are installed in the notebook due to the cell </span><code>!pip install -r requirements.txt</code><span>. Hopefully this should be enough enough for the self-contained section and for dependencies as well.</span></p><p><span>One just needs to execute the notebook that we provided and everything executes on it’s own. We explained various aspects of the code in the notebook as well. Some parameters can be inserted via input. Only requirements are </span><em><span>Python 3</span></em><span> (</span><em><span>ipykernel</span></em><span>) and </span><em><span>Jupyter Notebook</span></em><span>.</span></p><h1 id="Discussion" data-id="Discussion"><a class="anchor hidden-xs" href="#Discussion" title="Discussion"><span class="octicon octicon-link"></span></a><span>Discussion</span></h1><p><span>This section solely exists to present our findings and describe our opinions on them and how come they are like that. Please note that sometimes the results might differ (even when same data and model, but table vs. matrix) because we calculated these across different devices (sometimes Google Colab, Kaggle Notebook and also local devices), so the results might have some slight differences in terms of proportions here and there.</span></p><h2 id="News-Classification2" data-id="News-Classification"><a class="anchor hidden-xs" href="#News-Classification2" title="News-Classification2"><span class="octicon octicon-link"></span></a><span>News Classification</span></h2><h3 id="Grid-Search-logistic-regression-c01" data-id="Grid-Search-logistic-regression-c01"><a class="anchor hidden-xs" href="#Grid-Search-logistic-regression-c01" title="Grid-Search-logistic-regression-c01"><span class="octicon octicon-link"></span></a><span>Grid Search (logistic regression c=0.1)</span></h3><p><img src="https://i.imgur.com/UsaeG3h.png" alt="" loading="lazy"></p><p><span>As can be seen in the </span><strong><span>Models</span></strong><span> section, one can notice our results and come to the conclusion that logistic regression performs really well, including with the test data. This is not really a surprise since generally logistic regression is deemed as a good algorithm in </span><em><span>NLP</span></em><span> domains, such as text classification. Above, we can see that the majority of misclassified labels are the </span><strong><span>World</span></strong><span>, </span><strong><span>Business</span></strong><span> and </span><strong><span>Tech</span></strong><span> news labels. </span><strong><span>Sport</span></strong><span> news seems to be the most distinguishable. </span><strong><span>World</span></strong><span> and </span><strong><span>Business</span></strong><span> seem fairly logical why misclassification can happen, but in our opinion </span><strong><span>Tech</span></strong><span> was less ambigious, such as </span><strong><span>Sport</span></strong><span>, but apparently it does not seem so.</span></p><h3 id="RNN-model" data-id="RNN-model"><a class="anchor hidden-xs" href="#RNN-model" title="RNN-model"><span class="octicon octicon-link"></span></a><span>RNN model</span></h3><p><img src="https://i.imgur.com/XGJTAUM.png" alt="" loading="lazy"></p><p><span>Our </span><em><span>SimpleRNN</span></em><span> model don’t perform well as logistic regression, so we can see more misclassifications.</span></p><h3 id="Bidirectional-LSTM-model" data-id="Bidirectional-LSTM-model"><a class="anchor hidden-xs" href="#Bidirectional-LSTM-model" title="Bidirectional-LSTM-model"><span class="octicon octicon-link"></span></a><span>Bidirectional LSTM model</span></h3><p><img src="https://i.imgur.com/TVem1qI.png" alt="" loading="lazy"></p><p><span>Bidirectional LSTM model still dont provide better results in comparison with the Logistic Regression.</span></p><h3 id="DistilBERT" data-id="DistilBERT"><a class="anchor hidden-xs" href="#DistilBERT" title="DistilBERT"><span class="octicon octicon-link"></span></a><span>DistilBERT</span></h3><p><img src="https://i.imgur.com/FHJLk9W.png" alt="" loading="lazy"></p><p><img src="https://i.imgur.com/ulD8P42.png" alt="" loading="lazy"></p><p><span>The </span><em><span>BERT</span></em><span> model “understands” better the </span><em><span>Sport</span></em><span> news, as can be seen when looking at the misclassifications going from 149 to 69, and also </span><em><span>Business</span></em><span> and </span><em><span>Tech</span></em><span> news (from 362 to 274).</span></p><h2 id="Twitter-Data-Classification1" data-id="Twitter-Data-Classification"><a class="anchor hidden-xs" href="#Twitter-Data-Classification1" title="Twitter-Data-Classification1"><span class="octicon octicon-link"></span></a><span>Twitter Data Classification</span></h2><p><span>At first we tried to replicate what we did for the </span><em><span>News Classification</span></em><span> but this didn’t pan out the way we wished due to two simple factors. The first one being that data set has multi-labels whereas data set 2 has binary/boolean labels. This means we had to score our models differently. Second issue was that the two data sets had different averages of tokens (news had more on average than twitter), meaning our max. length had to be adjusted accordingly.</span></p><h3 id="Logistic-Regression-Grid-Search-c01" data-id="Logistic-Regression-Grid-Search-c01"><a class="anchor hidden-xs" href="#Logistic-Regression-Grid-Search-c01" title="Logistic-Regression-Grid-Search-c01"><span class="octicon octicon-link"></span></a><span>Logistic Regression (Grid Search c=0.1)</span></h3><p><span>Compared with the first data set we can already see with Logistic Regression that it’s more difficult to classify sentiment over topics. In the first data set we classify text regarding topics like </span><strong><span>Sport</span></strong><span>, </span><strong><span>Business</span></strong><span>, </span><strong><span>Tech</span></strong><span>, etc ; a lot of vocabulary is associated with those classes which made them easier to recognize (even for a human). While in the second data set we classify text regarding the satisfaction of individuals which is subjective and there is not really a  specific vocabulary associated with satisfiability. Also, even if an someone express disatisfaction it can be interpreted as satisfaction.</span></p><p><img src="https://i.imgur.com/IOipItP.png" alt="" loading="lazy"><br>
<span>The confusion matrix of the test data predicted by </span><em><span>Logistic Regression</span></em><span> shows that the model classify better satisfied texts than unsatisfied texts. But thanks to the high number of false positive we can just conclude that </span><em><span>Logistic Regression</span></em><span> has just a tendency to predict tweets as satisfied.</span></p><h3 id="RNN" data-id="RNN"><a class="anchor hidden-xs" href="#RNN" title="RNN"><span class="octicon octicon-link"></span></a><span>RNN</span></h3><p><span>The </span><em><span>RNN</span></em><span> is giving better results than Logistic Regression. Indeed we can observe more stability between True and False negative and in general the performances on the accuracy, f1-score and recall are better (around 0.745 for Logistic Regression and 0.75 for RNN).</span><br>
<img src="https://i.imgur.com/8bU5Gr7.png" alt="" loading="lazy"><br>
<img src="https://i.imgur.com/u6VXxXX.png" alt="" loading="lazy"></p><h3 id="Bidirectional-LSTM-model1" data-id="Bidirectional-LSTM-model"><a class="anchor hidden-xs" href="#Bidirectional-LSTM-model1" title="Bidirectional-LSTM-model1"><span class="octicon octicon-link"></span></a><span>Bidirectional LSTM model</span></h3><p><span>Here with the Bidirectional </span><em><span>LSTM</span></em><span> model we can observe similar results as for Logistic Regression : the model has a tendency to predict tweets as satisfied.</span><br>
<img src="https://i.imgur.com/nuHeFcM.png" alt="" loading="lazy"><br>
<img src="https://i.imgur.com/afy1jEC.png" alt="" loading="lazy"></p><h3 id="DistilBERT1" data-id="DistilBERT"><a class="anchor hidden-xs" href="#DistilBERT1" title="DistilBERT1"><span class="octicon octicon-link"></span></a><span>DistilBERT</span></h3><p><span>With </span><em><span>DistiBERT</span></em><span>, the curves and the confusion matrix show that the model performs as good as the </span><em><span>RNN</span></em><span> (75% accuracy).</span></p><p><span>In comparison with data set 1, the curves intersect later on the epochs. This represents the fact that </span><em><span>DistiBERT</span></em><span> is over-fitting faster for data set 1 than for data set 2. We think that this is due to the fact that it is easier, in text classification, to predict topics than sentiments.</span><br>
<img src="https://i.imgur.com/g7LEQUx.png" alt="" loading="lazy"></p><p><img src="https://i.imgur.com/RfH3pPU.png" alt="" loading="lazy"><br>
<img src="https://i.imgur.com/NYzgbkM.png" alt="" loading="lazy"><br>
<span>And, in comparison with the </span><em><span>RNN</span></em><span> model, the curves and the confusion matrix show that the model performs as good as the </span><em><span>RNN</span></em><span> (75% accuracy).</span></p><h2 id="Final-Comments" data-id="Final-Comments"><a class="anchor hidden-xs" href="#Final-Comments" title="Final-Comments"><span class="octicon octicon-link"></span></a><span>Final Comments</span></h2><p><span>Shallow learning plateaus whereas deep doesn’t will always be a short-coming. On the other hand deep learning only performs well with high-performance GPUs and well labeled data. These aspects should be the deciding factors when deciding between either</span></p><p><span>In general, for our 2 datasets, we managed to achieve really good results with </span><em><span>Logistic Regression</span></em><span> itself. We used Bag of Words approach for that. Our training time was just 55 seconds, while for the Neural Networks we achieved 87 seconds and 150 seconds for BERT. With BERT model we managed to achieve just 2% improvement. Which is still a lot for big amount of data, but the training time is much more.</span><br>
<span>Usually when it comes of model selection, as far the basic machine learning models are doing great job for classifying, we can use them in production.</span></p><p><span>Bidirectional layer is used for </span><em><span>NLP</span></em><span> when we want to get the semantics of the words in the scheme of the whole sentence. We use it often for text generation, next word recommendations and etc. We can see that those complex approaches are not increasing the accuracy in terms of classifying. We could extract good results only with basic algorithms.</span></p><p><strong><span>Improvements:</span></strong><br>
<span>For the future improvements we can approach vectorizing with </span><em><span>TF-IDF</span></em><span> for text Classification and compare it with Bag of Word approach.</span><br>
<span>Also when it comes to text embeddings in Neural Network we can use pre-train Word embeddings techniques such as </span><em><span>GloVe</span></em><span> or </span><em><span>Word2Vec</span></em><span>. Those approaches are useful for vectorizing the words and providing the possibility for having relations between them (the cosine distance between two vectors).</span></p></div>
    <div class="ui-toc dropup unselectable hidden-print" style="display:none;">
        <div class="pull-right dropdown">
            <a id="tocLabel" class="ui-toc-label btn btn-default" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false" title="Table of content">
                <i class="fa fa-bars"></i>
            </a>
            <ul id="ui-toc" class="ui-toc-dropdown dropdown-menu" aria-labelledby="tocLabel">
                <div class="toc"><ul class="nav">
<li><a href="#184702-Machine-Learning---Exercise-3-Report" title="184.702 Machine Learning - Exercise 3 Report">184.702 Machine Learning - Exercise 3 Report</a><ul class="nav">
<li><a href="#Deep-Learning---Text-Classification" title="Deep Learning - Text Classification">Deep Learning - Text Classification</a></li>
</ul>
</li>
<li><a href="#Introduction" title="Introduction">Introduction</a></li>
<li><a href="#Data" title="Data">Data</a><ul class="nav">
<li><a href="#Data-1-News-Classification" title="Data 1: News Classification">Data 1: News Classification</a></li>
<li><a href="#Data-2-Twitter-Data-classification" title="Data 2: Twitter Data classification">Data 2: Twitter Data classification</a></li>
</ul>
</li>
<li><a href="#Our-Approach" title="Our Approach">Our Approach</a><ul class="nav">
<li><a href="#Step-1-Defining-our-Text-Classification" title="Step 1: Defining our Text Classification">Step 1: Defining our Text Classification</a></li>
<li><a href="#Step-2-Import-Analyze-and-Preprocess-the-Data" title="Step 2: Import, Analyze and Preprocess the Data">Step 2: Import, Analyze and Preprocess the Data</a><ul class="nav">
<li><a href="#News-Classification" title="News Classification">News Classification</a></li>
<li><a href="#Twitter-Data-Classification" title="Twitter Data Classification">Twitter Data Classification</a></li>
</ul>
</li>
<li><a href="#Step-3-Models" title="Step 3: Models">Step 3: Models</a></li>
<li><a href="#News-Classification1" title="News Classification">News Classification</a></li>
<li><a href="#Twitter-Sentiment-Classification" title="Twitter Sentiment Classification">Twitter Sentiment Classification</a></li>
</ul>
</li>
<li><a href="#How-To" title="How-To">How-To</a></li>
<li><a href="#Discussion" title="Discussion">Discussion</a><ul class="nav">
<li><a href="#News-Classification2" title="News Classification">News Classification</a><ul class="nav">
<li><a href="#Grid-Search-logistic-regression-c01" title="Grid Search (logistic regression c=0.1)">Grid Search (logistic regression c=0.1)</a></li>
<li><a href="#RNN-model" title="RNN model">RNN model</a></li>
<li><a href="#Bidirectional-LSTM-model" title="Bidirectional LSTM model">Bidirectional LSTM model</a></li>
<li><a href="#DistilBERT" title="DistilBERT">DistilBERT</a></li>
</ul>
</li>
<li><a href="#Twitter-Data-Classification1" title="Twitter Data Classification">Twitter Data Classification</a><ul class="nav">
<li><a href="#Logistic-Regression-Grid-Search-c01" title="Logistic Regression (Grid Search c=0.1)">Logistic Regression (Grid Search c=0.1)</a></li>
<li><a href="#RNN" title="RNN">RNN</a></li>
<li><a href="#Bidirectional-LSTM-model1" title="Bidirectional LSTM model">Bidirectional LSTM model</a></li>
<li><a href="#DistilBERT1" title="DistilBERT">DistilBERT</a></li>
</ul>
</li>
<li><a href="#Final-Comments" title="Final Comments">Final Comments</a></li>
</ul>
</li>
</ul>
</div><div class="toc-menu"><a class="expand-toggle" href="#">Expand all</a><a class="back-to-top" href="#">Back to top</a><a class="go-to-bottom" href="#">Go to bottom</a></div>
            </ul>
        </div>
    </div>
    <div id="ui-toc-affix" class="ui-affix-toc ui-toc-dropdown unselectable hidden-print" data-spy="affix" style="top:17px;display:none;" null null>
        <div class="toc"><ul class="nav">
<li><a href="#184702-Machine-Learning---Exercise-3-Report" title="184.702 Machine Learning - Exercise 3 Report">184.702 Machine Learning - Exercise 3 Report</a><ul class="nav">
<li><a href="#Deep-Learning---Text-Classification" title="Deep Learning - Text Classification">Deep Learning - Text Classification</a></li>
</ul>
</li>
<li><a href="#Introduction" title="Introduction">Introduction</a></li>
<li><a href="#Data" title="Data">Data</a><ul class="nav">
<li><a href="#Data-1-News-Classification" title="Data 1: News Classification">Data 1: News Classification</a></li>
<li><a href="#Data-2-Twitter-Data-classification" title="Data 2: Twitter Data classification">Data 2: Twitter Data classification</a></li>
</ul>
</li>
<li><a href="#Our-Approach" title="Our Approach">Our Approach</a><ul class="nav">
<li><a href="#Step-1-Defining-our-Text-Classification" title="Step 1: Defining our Text Classification">Step 1: Defining our Text Classification</a></li>
<li><a href="#Step-2-Import-Analyze-and-Preprocess-the-Data" title="Step 2: Import, Analyze and Preprocess the Data">Step 2: Import, Analyze and Preprocess the Data</a><ul class="nav">
<li><a href="#News-Classification" title="News Classification">News Classification</a></li>
<li><a href="#Twitter-Data-Classification" title="Twitter Data Classification">Twitter Data Classification</a></li>
</ul>
</li>
<li><a href="#Step-3-Models" title="Step 3: Models">Step 3: Models</a></li>
<li><a href="#News-Classification1" title="News Classification">News Classification</a></li>
<li><a href="#Twitter-Sentiment-Classification" title="Twitter Sentiment Classification">Twitter Sentiment Classification</a></li>
</ul>
</li>
<li><a href="#How-To" title="How-To">How-To</a></li>
<li><a href="#Discussion" title="Discussion">Discussion</a><ul class="nav">
<li><a href="#News-Classification2" title="News Classification">News Classification</a><ul class="nav">
<li><a href="#Grid-Search-logistic-regression-c01" title="Grid Search (logistic regression c=0.1)">Grid Search (logistic regression c=0.1)</a></li>
<li><a href="#RNN-model" title="RNN model">RNN model</a></li>
<li><a href="#Bidirectional-LSTM-model" title="Bidirectional LSTM model">Bidirectional LSTM model</a></li>
<li><a href="#DistilBERT" title="DistilBERT">DistilBERT</a></li>
</ul>
</li>
<li><a href="#Twitter-Data-Classification1" title="Twitter Data Classification">Twitter Data Classification</a><ul class="nav">
<li><a href="#Logistic-Regression-Grid-Search-c01" title="Logistic Regression (Grid Search c=0.1)">Logistic Regression (Grid Search c=0.1)</a></li>
<li><a href="#RNN" title="RNN">RNN</a></li>
<li><a href="#Bidirectional-LSTM-model1" title="Bidirectional LSTM model">Bidirectional LSTM model</a></li>
<li><a href="#DistilBERT1" title="DistilBERT">DistilBERT</a></li>
</ul>
</li>
<li><a href="#Final-Comments" title="Final Comments">Final Comments</a></li>
</ul>
</li>
</ul>
</div><div class="toc-menu"><a class="expand-toggle" href="#">Expand all</a><a class="back-to-top" href="#">Back to top</a><a class="go-to-bottom" href="#">Go to bottom</a></div>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.min.js" integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous" defer></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gist-embed/2.6.0/gist-embed.min.js" integrity="sha256-KyF2D6xPIJUW5sUDSs93vWyZm+1RzIpKCexxElmxl8g=" crossorigin="anonymous" defer></script>
    <script>
        var markdown = $(".markdown-body");
        //smooth all hash trigger scrolling
        function smoothHashScroll() {
            var hashElements = $("a[href^='#']").toArray();
            for (var i = 0; i < hashElements.length; i++) {
                var element = hashElements[i];
                var $element = $(element);
                var hash = element.hash;
                if (hash) {
                    $element.on('click', function (e) {
                        // store hash
                        var hash = this.hash;
                        if ($(hash).length <= 0) return;
                        // prevent default anchor click behavior
                        e.preventDefault();
                        // animate
                        $('body, html').stop(true, true).animate({
                            scrollTop: $(hash).offset().top
                        }, 100, "linear", function () {
                            // when done, add hash to url
                            // (default click behaviour)
                            window.location.hash = hash;
                        });
                    });
                }
            }
        }

        smoothHashScroll();
        var toc = $('.ui-toc');
        var tocAffix = $('.ui-affix-toc');
        var tocDropdown = $('.ui-toc-dropdown');
        //toc
        tocDropdown.click(function (e) {
            e.stopPropagation();
        });

        var enoughForAffixToc = true;

        function generateScrollspy() {
            $(document.body).scrollspy({
                target: ''
            });
            $(document.body).scrollspy('refresh');
            if (enoughForAffixToc) {
                toc.hide();
                tocAffix.show();
            } else {
                tocAffix.hide();
                toc.show();
            }
            $(document.body).scroll();
        }

        function windowResize() {
            //toc right
            var paddingRight = parseFloat(markdown.css('padding-right'));
            var right = ($(window).width() - (markdown.offset().left + markdown.outerWidth() - paddingRight));
            toc.css('right', right + 'px');
            //affix toc left
            var newbool;
            var rightMargin = (markdown.parent().outerWidth() - markdown.outerWidth()) / 2;
            //for ipad or wider device
            if (rightMargin >= 133) {
                newbool = true;
                var affixLeftMargin = (tocAffix.outerWidth() - tocAffix.width()) / 2;
                var left = markdown.offset().left + markdown.outerWidth() - affixLeftMargin;
                tocAffix.css('left', left + 'px');
            } else {
                newbool = false;
            }
            if (newbool != enoughForAffixToc) {
                enoughForAffixToc = newbool;
                generateScrollspy();
            }
        }
        $(window).resize(function () {
            windowResize();
        });
        $(document).ready(function () {
            windowResize();
            generateScrollspy();
        });

        //remove hash
        function removeHash() {
            window.location.hash = '';
        }

        var backtotop = $('.back-to-top');
        var gotobottom = $('.go-to-bottom');

        backtotop.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            if (scrollToTop)
                scrollToTop();
            removeHash();
        });
        gotobottom.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            if (scrollToBottom)
                scrollToBottom();
            removeHash();
        });

        var toggle = $('.expand-toggle');
        var tocExpand = false;

        checkExpandToggle();
        toggle.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            tocExpand = !tocExpand;
            checkExpandToggle();
        })

        function checkExpandToggle () {
            var toc = $('.ui-toc-dropdown .toc');
            var toggle = $('.expand-toggle');
            if (!tocExpand) {
                toc.removeClass('expand');
                toggle.text('Expand all');
            } else {
                toc.addClass('expand');
                toggle.text('Collapse all');
            }
        }

        function scrollToTop() {
            $('body, html').stop(true, true).animate({
                scrollTop: 0
            }, 100, "linear");
        }

        function scrollToBottom() {
            $('body, html').stop(true, true).animate({
                scrollTop: $(document.body)[0].scrollHeight
            }, 100, "linear");
        }
    </script>
</body>

</html>
