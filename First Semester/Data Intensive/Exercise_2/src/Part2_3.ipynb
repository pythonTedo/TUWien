{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f69c66",
   "metadata": {},
   "source": [
    "# Teodor Chakarov, id: 12141198\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e70aa7-fd29-4c12-a583-5c962cc63ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StopWordsRemover, StringIndexer, HashingTF, IDF \n",
    "from pyspark.ml.feature import ChiSqSelector, PCA\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, explode, array_contains, array_remove\n",
    "from pyspark.sql.functions import regexp_replace, trim, col, lower, concat\n",
    "import re\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import os\n",
    "from array import array\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.rdd import RDD\n",
    "\n",
    "from pyspark.ml.feature import Normalizer \n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest, LogisticRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b7424b0-fb2b-4dd0-85c7-bf1bcaae1848",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=pyspark.SparkConf().setAppName('SparkApp1').setMaster('local')\n",
    "sc=pyspark.SparkContext(conf=conf)\n",
    "spark=SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c45e284",
   "metadata": {},
   "source": [
    "# Reading the data and preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c596a13a",
   "metadata": {},
   "source": [
    "Here from all the data I am selecting the needed columns **reviewText** and **category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7fb7b059-783e-4fe6-91df-9616f513546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"reviews_devset.json\")\n",
    "df_selected = df.select('reviewText', 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "67f1db72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(reviewText=\"This was a gift for my other husband.  He's making us things from it all the time and we love the food.  Directions are simple, easy to read and interpret, and fun to make.  We all love different kinds of cuisine and Raichlen provides recipes from everywhere along the barbecue trail as he calls it. Get it and just open a page.  Have at it.  You'll love the food and it has provided us with an insight into the culture that produced it. It's all about broadening horizons.  Yum!!\", category='Patio_Lawn_and_Garde'),\n",
       " Row(reviewText='This is a very nice spreader.  It feels very solid and the pneumatic tires give it great maneuverability and handling over bumps.  The control arm is solid metal, not a cable, which gives you precise control and will last a long time.  The settings take some experimentation with your various products to get it right, but that is true of any spreader.  It has good distribution... probably flings material a little farther on the right side than the left, but it is far more even than my crappy Edgeguard ever was.', category='Patio_Lawn_and_Garde')]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f5baaa",
   "metadata": {},
   "source": [
    "We can see, we have two records with the review and the category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59034c63",
   "metadata": {},
   "source": [
    "## Building the preprocess pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "42c85f61-f10f-40a3-92c6-2dfec746ba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"reviewText\", outputCol=\"words\") # tokenizer\n",
    "stopwords  = StopWordsRemover.loadDefaultStopWords(\"english\")             # loading the stopwords\n",
    "remover = StopWordsRemover(inputCol = \"words\", outputCol = \"filtered\", stopWords=stopwords)    # removing the stopwords from english\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"tfs\")               # calculating the therm frequencies \n",
    "idf = IDF(inputCol='tfs', outputCol='idfs', minDocFreq=1)                 # calculatinf th eidfs values for all documents\n",
    "stringIndexer = StringIndexer(inputCol=\"category\", outputCol=\"labeled\")   # Label encoder\n",
    "selector = ChiSqSelector(numTopFeatures=2000, featuresCol=\"idfs\",         # chi_value selector top 2000 values\n",
    "                         outputCol=\"selectedFeatures\", labelCol=\"labeled\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e3b8b4",
   "metadata": {},
   "source": [
    "Initializing the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f873e9c7-f27d-41db-bc44-d6319c592b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[regexTokenizer, remover, hashingTF, idf, stringIndexer, selector])\n",
    "df_after = pipeline.fit(df_selected)\n",
    "df_after = df_after.transform(df_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f6c770bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(reviewText=\"This was a gift for my other husband.  He's making us things from it all the time and we love the food.  Directions are simple, easy to read and interpret, and fun to make.  We all love different kinds of cuisine and Raichlen provides recipes from everywhere along the barbecue trail as he calls it. Get it and just open a page.  Have at it.  You'll love the food and it has provided us with an insight into the culture that produced it. It's all about broadening horizons.  Yum!!\", category='Patio_Lawn_and_Garde', words=['this', 'was', 'a', 'gift', 'for', 'my', 'other', 'husband.', \"he's\", 'making', 'us', 'things', 'from', 'it', 'all', 'the', 'time', 'and', 'we', 'love', 'the', 'food.', 'directions', 'are', 'simple,', 'easy', 'to', 'read', 'and', 'interpret,', 'and', 'fun', 'to', 'make.', 'we', 'all', 'love', 'different', 'kinds', 'of', 'cuisine', 'and', 'raichlen', 'provides', 'recipes', 'from', 'everywhere', 'along', 'the', 'barbecue', 'trail', 'as', 'he', 'calls', 'it.', 'get', 'it', 'and', 'just', 'open', 'a', 'page.', 'have', 'at', 'it.', \"you'll\", 'love', 'the', 'food', 'and', 'it', 'has', 'provided', 'us', 'with', 'an', 'insight', 'into', 'the', 'culture', 'that', 'produced', 'it.', \"it's\", 'all', 'about', 'broadening', 'horizons.', 'yum!!'], filtered=['gift', 'husband.', 'making', 'us', 'things', 'time', 'love', 'food.', 'directions', 'simple,', 'easy', 'read', 'interpret,', 'fun', 'make.', 'love', 'different', 'kinds', 'cuisine', 'raichlen', 'provides', 'recipes', 'everywhere', 'along', 'barbecue', 'trail', 'calls', 'it.', 'get', 'open', 'page.', 'it.', 'love', 'food', 'provided', 'us', 'insight', 'culture', 'produced', 'it.', 'broadening', 'horizons.', 'yum!!'], tfs=SparseVector(262144, {7588: 1.0, 15377: 1.0, 23087: 1.0, 30899: 1.0, 46309: 1.0, 53570: 1.0, 65848: 1.0, 66042: 1.0, 87374: 1.0, 90859: 1.0, 96984: 1.0, 97165: 1.0, 97963: 1.0, 101581: 1.0, 109156: 2.0, 111224: 1.0, 121133: 1.0, 121367: 1.0, 121517: 1.0, 141863: 1.0, 143501: 3.0, 151876: 1.0, 156902: 1.0, 162444: 1.0, 166936: 1.0, 169527: 1.0, 177381: 1.0, 186480: 3.0, 201547: 1.0, 206225: 1.0, 211736: 1.0, 214322: 1.0, 214676: 1.0, 216170: 1.0, 230406: 1.0, 232869: 1.0, 248069: 1.0, 252722: 1.0}), idfs=SparseVector(262144, {7588: 5.23, 15377: 6.6022, 23087: 3.4679, 30899: 5.837, 46309: 5.8028, 53570: 2.132, 65848: 5.7067, 66042: 5.3218, 87374: 5.5746, 90859: 5.0231, 96984: 2.5814, 97165: 9.1956, 97963: 9.4833, 101581: 9.6656, 109156: 6.9563, 111224: 6.9443, 121133: 4.7225, 121367: 4.6235, 121517: 2.2719, 141863: 9.8888, 143501: 6.4475, 151876: 9.1956, 156902: 6.5389, 162444: 6.1571, 166936: 3.8443, 169527: 4.262, 177381: 6.3334, 186480: 5.8384, 201547: 3.114, 206225: 9.6656, 211736: 5.1703, 214322: 8.7901, 214676: 3.2388, 216170: 5.8413, 230406: 4.1587, 232869: 5.6367, 248069: 3.7834, 252722: 1.9519}), labeled=18.0, selectedFeatures=SparseVector(2000, {404: 3.4679, 779: 5.8028, 887: 2.132, 1103: 5.7067, 1108: 5.3218, 1461: 5.5746, 1653: 2.5814, 1858: 6.9563}))]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_after.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8bbf79",
   "metadata": {},
   "source": [
    "Here is the output of the first record after the preprocess. We have those steps:\n",
    "- reviewText, category\n",
    "- words (tokenized)\n",
    "- filtered (stopwords)\n",
    "- tf\n",
    "- idf\n",
    "- labeled - Label encoded\n",
    "- chi selector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37e0afa",
   "metadata": {},
   "source": [
    "For the chi selector we have 2000 long vector with chi values of the words. Sparse vector represents not the 0 values. We have on which position we have value > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6df15544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "selectedFeatures    (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "labeled                                                          18.0\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32376023",
   "metadata": {},
   "source": [
    "### Extracting as txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f77014c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values_from_vector(vector):\n",
    "    return vector.values.tolist()\n",
    "\n",
    "def extract_keys_from_vector(vector):\n",
    "    return vector.indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6d09986",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = {}\n",
    "\n",
    "for i in range(78829):\n",
    "    curdf = df_pd.iloc[i]\n",
    "    if (str(curdf.labeled) not in li.keys()):\n",
    "        li[f\"{curdf.labeled}\"] = {}\n",
    "    for m, k in enumerate(extract_keys_from_vector(curdf.selectedFeatures)):\n",
    "        if (k not in li[f\"{curdf.labeled}\"].keys()):\n",
    "            li[f\"{curdf.labeled}\"][k] = extract_values_from_vector(curdf.selectedFeatures)[m]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff86d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile = open(\"output_ds.txt\", \"w\")\n",
    "for key,el in li.items():\n",
    "        textfile.write(f\"{key, el}\" + \"\\n\")\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0b68fa",
   "metadata": {},
   "source": [
    "# Machine Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c132ca4",
   "metadata": {},
   "source": [
    "Splitting the data to train, test and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8b173a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df_after_1.select(\"selectedFeatures\", \"labeled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4b21d596",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, next_data) = train_data.randomSplit([0.7,0.3], seed=24)\n",
    "(val, test) = next_data.randomSplit([0.8,0.2], seed=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ef9bedc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55097, 2)\n"
     ]
    }
   ],
   "source": [
    "print((train.count(), len(train.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "19aa2782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18993, 2)\n"
     ]
    }
   ],
   "source": [
    "print((val.count(), len(val.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e1616a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4739, 2)\n"
     ]
    }
   ],
   "source": [
    "print((test.count(), len(test.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fd74ed",
   "metadata": {},
   "source": [
    "## Building the ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "094ae19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer(inputCol=\"selectedFeatures\", outputCol=\"normFeatures\", p=1.0)  # normaliznig the features (chi values)\n",
    "svm = LinearSVC(labelCol=\"labeled\")                                                    # Linear Support Vector Machines\n",
    "ovr = OneVsRest(classifier=svm, featuresCol='normFeatures',labelCol='labeled')         # Multiclass classification method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "632cf522",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline(stages = [normalizer, ovr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b967b17",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "\n",
    "Building Cross-validation technnique - for preventing overfitting and also hyper-paramether search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c9156f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.0, 0.1]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline2,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(labelCol=\"labeled\"),\n",
    "                          numFolds=5)\n",
    "\n",
    "cvModel = crossval.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aba0738",
   "metadata": {},
   "source": [
    "F1 - score for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "de2b4e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5346165509987915"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = cvModel.transform(val)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"labeled\",predictionCol=\"prediction\")\n",
    "evaluator.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3773f1cb",
   "metadata": {},
   "source": [
    "F1 - score for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f92ce8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = cvModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f0e2aafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5476418235041257"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"labeled\",predictionCol=\"prediction\")\n",
    "evaluator.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9f3b1d",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2621a32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "ovr2 = OneVsRest(classifier=lr, featuresCol='normFeatures',labelCol='labeled')\n",
    "\n",
    "pipeline3 = Pipeline(stages = [normalizer, ovr2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "547ec458",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid1 = ParamGridBuilder() \\\n",
    "    .addGrid(lr.maxIter, [500]) \\\n",
    "    .build()\n",
    "\n",
    "crossval1 = CrossValidator(estimator=pipeline3,\n",
    "                          estimatorParamMaps=paramGrid1,\n",
    "                          evaluator=MulticlassClassificationEvaluator(labelCol=\"labeled\"),\n",
    "                          numFolds=2)\n",
    "\n",
    "cvModel1 = crossval1.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "3e59ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = cvModel1.transform(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f01d5ec",
   "metadata": {},
   "source": [
    "F1 score for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "bced91fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5234466603538767"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"labeled\",predictionCol=\"prediction\")\n",
    "evaluator.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e639f996",
   "metadata": {},
   "source": [
    "F1 score for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "60814a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = cvModel1.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "7c918eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5430884865303869"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"labeled\",predictionCol=\"prediction\")\n",
    "evaluator.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3804c296",
   "metadata": {},
   "source": [
    "## Using only TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5ef021fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|          reviewText|            category|\n",
      "+--------------------+--------------------+\n",
      "|This was a gift f...|Patio_Lawn_and_Garde|\n",
      "|This is a very ni...|Patio_Lawn_and_Garde|\n",
      "|The metal base wi...|Patio_Lawn_and_Garde|\n",
      "|For the most part...|Patio_Lawn_and_Garde|\n",
      "|This hose is supp...|Patio_Lawn_and_Garde|\n",
      "|This tool works v...|Patio_Lawn_and_Garde|\n",
      "|This product is a...|Patio_Lawn_and_Garde|\n",
      "|I was excited to ...|Patio_Lawn_and_Garde|\n",
      "|I purchased the L...|Patio_Lawn_and_Garde|\n",
      "|Never used a manu...|Patio_Lawn_and_Garde|\n",
      "|Good price. Good ...|Patio_Lawn_and_Garde|\n",
      "|I have owned the ...|Patio_Lawn_and_Garde|\n",
      "|I had \"won\" a sim...|Patio_Lawn_and_Garde|\n",
      "|The birds ate all...|Patio_Lawn_and_Garde|\n",
      "|Bought last summe...|Patio_Lawn_and_Garde|\n",
      "|I knew I had a mo...|Patio_Lawn_and_Garde|\n",
      "|I was a little wo...|Patio_Lawn_and_Garde|\n",
      "|I have used this ...|Patio_Lawn_and_Garde|\n",
      "|I actually do not...|Patio_Lawn_and_Garde|\n",
      "|Just what I  expe...|Patio_Lawn_and_Garde|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_selected.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b9ef52",
   "metadata": {},
   "source": [
    "Again splitting the data to train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "df905d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train1, next_data1) = df_selected.randomSplit([0.7,0.3], seed=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "eaf6d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(val1, test1) = next_data1.randomSplit([0.8,0.2], seed=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5a3d1b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer1 = RegexTokenizer(inputCol=\"reviewText\", outputCol=\"words\")\n",
    "stopwords1 = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "remover1 = StopWordsRemover(inputCol = \"words\", outputCol = \"filtered\", stopWords=stopwords)\n",
    "hashingTF1 = HashingTF(inputCol=\"filtered\", outputCol=\"tfs\")\n",
    "idf1 = IDF(inputCol='tfs', outputCol='idfs', minDocFreq=1)\n",
    "stringIndexer1 = StringIndexer(inputCol=\"category\", outputCol=\"labeled\")\n",
    "normalizer1 = Normalizer(inputCol=\"idfs\", outputCol=\"normFeatures\", p=1.0)\n",
    "#pca = PCA(k = 15, inputCol = \"normFeatures\", outputCol=\"pca\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8a3ae657",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_1 = LinearSVC()\n",
    "ovr3 = OneVsRest(classifier=svm_1, featuresCol='normFeatures',labelCol='labeled')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d34500f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline4 = Pipeline(stages=[regexTokenizer1, remover1, hashingTF1, idf1, stringIndexer1, normalizer1, ovr3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "41d6148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid2 = ParamGridBuilder() \\\n",
    "    .addGrid(svm_1.regParam, [0.1]) \\\n",
    "    .build()\n",
    "\n",
    "crossval3 = CrossValidator(estimator=pipeline4,\n",
    "                          estimatorParamMaps=paramGrid2,\n",
    "                          evaluator=MulticlassClassificationEvaluator(labelCol=\"labeled\"),\n",
    "                          numFolds=2)\n",
    "\n",
    "cvModel3 = crossval3.fit(df_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36869894",
   "metadata": {},
   "source": [
    "**validation f1 score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ac853158",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction3 = cvModel3.transform(val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "040bdff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9864421286679639"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"labeled\",predictionCol=\"prediction\")\n",
    "evaluator.evaluate(prediction3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7528a691",
   "metadata": {},
   "source": [
    "**test f1 score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "9ba2088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction3 = cvModel3.transform(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "980314f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9875127566451318"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"labeled\",predictionCol=\"prediction\")\n",
    "evaluator.evaluate(prediction3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322ab3b2",
   "metadata": {},
   "source": [
    "# Conslusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b746d675",
   "metadata": {},
   "source": [
    "We saw how the stram of the data with the help of Pipeline tool, we can specify all the needed steps from reading the data to making predictions.\n",
    "\n",
    "Support Vector Machines are really powerful but slow for fitting big datasets. Both SVM and Logistig regression scored around 50% with chi selector. We had vector with 2000 features but a little values actually bring the knowledge.\n",
    "\n",
    "In the last step I fitted only with TF-IDF in SVM and we scored 98% on both validation and tesing sets. We have again hudge dimension.\n",
    "Although I tried to inplement PCA dimensionality reduction technique after normalizing the TF-IDF but I had some computational issues. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
