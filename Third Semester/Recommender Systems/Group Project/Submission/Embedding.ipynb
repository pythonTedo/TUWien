{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "682f38d5-ef8d-4b72-846f-122e86e30440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.8.1\n",
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.0.223)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.5.9)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.1)\n",
      "Requirement already satisfied: langchainplus-sdk<0.0.21,>=0.0.20 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.20)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.10.11)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.28.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.1.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Collecting sentence_transformers\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Collecting torch>=1.6.0\n",
      "  Using cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.23.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.10.1)\n",
      "Collecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.16.2-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.5/268.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
      "  Using cached transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.64.1)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (3.8.1)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.4.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.3.0)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.0)\n",
      "Collecting triton==2.0.0\n",
      "  Using cached triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91\n",
      "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.0)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3\n",
      "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91\n",
      "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence_transformers) (67.1.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence_transformers) (0.38.4)\n",
      "Collecting cmake\n",
      "  Using cached cmake-3.26.4-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
      "Collecting lit\n",
      "  Using cached lit-16.0.6-py3-none-any.whl\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.10.31)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Using cached safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->sentence_transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers) (9.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
      "Installing collected packages: tokenizers, sentencepiece, safetensors, lit, cmake, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, filelock, nvidia-cusolver-cu11, nvidia-cudnn-cu11, huggingface-hub, transformers, triton, torch, torchvision, sentence_transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 2.1.1\n",
      "    Uninstalling transformers-2.1.1:\n",
      "      Successfully uninstalled transformers-2.1.1\n",
      "Successfully installed cmake-3.26.4 filelock-3.12.2 huggingface-hub-0.16.2 lit-16.0.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 safetensors-0.3.1 sentence_transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.13.3 torch-2.0.1 torchvision-0.15.2 transformers-4.30.2 triton-2.0.0\n",
      "Collecting openai\n",
      "  Using cached openai-0.27.8-py3-none-any.whl (73 kB)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.10/site-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (22.2.0)\n",
      "Installing collected packages: openai\n",
      "Successfully installed openai-0.27.8\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2022.10.31)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.28.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install langchain\n",
    "!pip install sentence_transformers\n",
    "!pip install openai\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb88f831-9347-4a89-8b1c-e74db873cffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/e11709501/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import nltk as nlp\n",
    "nlp.download('stopwords')\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e5c573a-23b9-4120-94a9-0846606d8d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_csv(\"../data/cleaned_articles.csv\")\n",
    "merged.head()\n",
    "merged = merged.drop(columns = [\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b76aec1-dc66-43ec-bf3f-1f3e2fa9c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = merged.paragraphs+ \" \" +merged.title + \" \" + merged.ressort.fillna(\"\") + \" \" + merged.authors.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "355ef5b0-1476-4f2f-a1d9-c940f696856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(review):\n",
    "    if isinstance(review, str):\n",
    "        review = review.lower()\n",
    "        review = re.sub('[^a-z A-Z 0-9-]+', '', review)\n",
    "        review = \" \".join([word for word in review.split() if word not in stopwords.words('german')])\n",
    "        \n",
    "        return review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4a90bb-958c-4d55-b81e-64ad0c6c70f5",
   "metadata": {},
   "source": [
    "Cleaning of the text takes some time. Therefore run it if it is neccesary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d354d96-2595-4e9f-9439-5d9955b624cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cleaned = text.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e8ca4b-c9f3-47ce-a34f-3903c125a3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"text_cleaned\"] = text_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a8cf9d-9537-4beb-9f51-1e8780acafda",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2681c3-304a-4005-b857-f307a7f8f24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(\"../data/cleaned_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689a33fe-69f5-440c-84f3-c3ffaa8d6c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"text_cleaned\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93994bd0-bf8e-493d-ab7c-9ceb46b88aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>ressort</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FALTER_201512234F1D30CEA9</td>\n",
       "      <td>\"Bewundere Frau Merkel über alles\"</td>\n",
       "      <td>['Kinderwagen drängen sich bei der Eingangstür...</td>\n",
       "      <td>Steiermark</td>\n",
       "      <td>gerlinde pölsler</td>\n",
       "      <td>2015-12-23 00:00:00+00:00</td>\n",
       "      <td>kinderwagen drngen eingangstr wolfgang puchers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FALTER_2015122382119EA87A</td>\n",
       "      <td>Wildbretter</td>\n",
       "      <td>['Das Handbuch der Kolumnenschreiberei sieht v...</td>\n",
       "      <td>Falters Zoo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-12-23 00:00:00+00:00</td>\n",
       "      <td>handbuch kolumnenschreiberei sieht letzte glos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>FALTER_2015122317D031535C</td>\n",
       "      <td>Warum es ganz normal sein kann, zwei Zuhause z...</td>\n",
       "      <td>['Xenia, Fotografin, 22', 'Ich habe bis vor zw...</td>\n",
       "      <td>Stadtleben</td>\n",
       "      <td>barbara tóth</td>\n",
       "      <td>2015-12-23 00:00:00+00:00</td>\n",
       "      <td>xenia fotografin 22 zwei jahren tag zuhause ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>FALTER_20151223D853291AAA</td>\n",
       "      <td>Der Lerchenfisch</td>\n",
       "      <td>['Zuerst Korrektur eines Irrtums: Nicht die AM...</td>\n",
       "      <td>Stadtleben</td>\n",
       "      <td>florian holzer</td>\n",
       "      <td>2015-12-23 00:00:00+00:00</td>\n",
       "      <td>zuerst korrektur irrtums ama betrieb restauran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>FALTER_201512238A0DEB6E2D</td>\n",
       "      <td>Uhudler-Orbán und Kernölamazonen</td>\n",
       "      <td>['Wann feiert ein Kabarettist eigentlich Silve...</td>\n",
       "      <td>Lexikon</td>\n",
       "      <td>stefanie panzenböck, sara schausberger</td>\n",
       "      <td>2015-12-23 00:00:00+00:00</td>\n",
       "      <td>wann feiert kabarettist eigentlich silvester a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5911</th>\n",
       "      <td>5911</td>\n",
       "      <td>FALTER_20150114D1B1464B21</td>\n",
       "      <td>Achte Ausgabe des Festivals in between</td>\n",
       "      <td>['Das Konzept ist so einfach wie schlüssig: Zu...</td>\n",
       "      <td>Lexikon</td>\n",
       "      <td>gs</td>\n",
       "      <td>2015-01-14 00:00:00+00:00</td>\n",
       "      <td>konzept einfach schlssig zugereiste wiener mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5912</th>\n",
       "      <td>5912</td>\n",
       "      <td>FALTER_20150114100173AA99</td>\n",
       "      <td>Punkrock der Marke \"Ned deppert sein!\"</td>\n",
       "      <td>['Drei Songs in viereinhalb Minuten: Lime Crus...</td>\n",
       "      <td>Lexikon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-14 00:00:00+00:00</td>\n",
       "      <td>drei songs viereinhalb minuten lime crush setz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>5913</td>\n",
       "      <td>FALTER_201501144F8F9DDBEE</td>\n",
       "      <td>Mit einem Flüchtling in der WG: Neue Initiativ...</td>\n",
       "      <td>['Warum müssen Menschen, die vor Krieg und Ele...</td>\n",
       "      <td>Politik</td>\n",
       "      <td>benedikt narodoslawsky</td>\n",
       "      <td>2015-01-14 00:00:00+00:00</td>\n",
       "      <td>warum mssen menschen krieg elend flchten masse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>5914</td>\n",
       "      <td>FALTER_201501143FF6C01FA5</td>\n",
       "      <td>Büchersonntag in Hietzing</td>\n",
       "      <td>['Sammler sind Getriebene, das gilt auch für B...</td>\n",
       "      <td>Lexikon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-14 00:00:00+00:00</td>\n",
       "      <td>sammler getriebene gilt fr bchersammler seit 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>5915</td>\n",
       "      <td>FALTER_20150114D27133E690</td>\n",
       "      <td>Neuer Floor, neue Party: ein guter Start ins P...</td>\n",
       "      <td>['Die Kickdrum zischt und dampft, die Snares r...</td>\n",
       "      <td>Lexikon</td>\n",
       "      <td>katharina seidler</td>\n",
       "      <td>2015-01-14 00:00:00+00:00</td>\n",
       "      <td>kickdrum zischt dampft snares rollen triolen h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5916 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                 article_id  \\\n",
       "0              0  FALTER_201512234F1D30CEA9   \n",
       "1              1  FALTER_2015122382119EA87A   \n",
       "2              2  FALTER_2015122317D031535C   \n",
       "3              3  FALTER_20151223D853291AAA   \n",
       "4              4  FALTER_201512238A0DEB6E2D   \n",
       "...          ...                        ...   \n",
       "5911        5911  FALTER_20150114D1B1464B21   \n",
       "5912        5912  FALTER_20150114100173AA99   \n",
       "5913        5913  FALTER_201501144F8F9DDBEE   \n",
       "5914        5914  FALTER_201501143FF6C01FA5   \n",
       "5915        5915  FALTER_20150114D27133E690   \n",
       "\n",
       "                                                  title  \\\n",
       "0                    \"Bewundere Frau Merkel über alles\"   \n",
       "1                                           Wildbretter   \n",
       "2     Warum es ganz normal sein kann, zwei Zuhause z...   \n",
       "3                                      Der Lerchenfisch   \n",
       "4                      Uhudler-Orbán und Kernölamazonen   \n",
       "...                                                 ...   \n",
       "5911             Achte Ausgabe des Festivals in between   \n",
       "5912             Punkrock der Marke \"Ned deppert sein!\"   \n",
       "5913  Mit einem Flüchtling in der WG: Neue Initiativ...   \n",
       "5914                          Büchersonntag in Hietzing   \n",
       "5915  Neuer Floor, neue Party: ein guter Start ins P...   \n",
       "\n",
       "                                             paragraphs      ressort  \\\n",
       "0     ['Kinderwagen drängen sich bei der Eingangstür...   Steiermark   \n",
       "1     ['Das Handbuch der Kolumnenschreiberei sieht v...  Falters Zoo   \n",
       "2     ['Xenia, Fotografin, 22', 'Ich habe bis vor zw...   Stadtleben   \n",
       "3     ['Zuerst Korrektur eines Irrtums: Nicht die AM...   Stadtleben   \n",
       "4     ['Wann feiert ein Kabarettist eigentlich Silve...      Lexikon   \n",
       "...                                                 ...          ...   \n",
       "5911  ['Das Konzept ist so einfach wie schlüssig: Zu...      Lexikon   \n",
       "5912  ['Drei Songs in viereinhalb Minuten: Lime Crus...      Lexikon   \n",
       "5913  ['Warum müssen Menschen, die vor Krieg und Ele...      Politik   \n",
       "5914  ['Sammler sind Getriebene, das gilt auch für B...      Lexikon   \n",
       "5915  ['Die Kickdrum zischt und dampft, die Snares r...      Lexikon   \n",
       "\n",
       "                                     authors                       date  \\\n",
       "0                           gerlinde pölsler  2015-12-23 00:00:00+00:00   \n",
       "1                                        NaN  2015-12-23 00:00:00+00:00   \n",
       "2                               barbara tóth  2015-12-23 00:00:00+00:00   \n",
       "3                             florian holzer  2015-12-23 00:00:00+00:00   \n",
       "4     stefanie panzenböck, sara schausberger  2015-12-23 00:00:00+00:00   \n",
       "...                                      ...                        ...   \n",
       "5911                                      gs  2015-01-14 00:00:00+00:00   \n",
       "5912                                     NaN  2015-01-14 00:00:00+00:00   \n",
       "5913                  benedikt narodoslawsky  2015-01-14 00:00:00+00:00   \n",
       "5914                                     NaN  2015-01-14 00:00:00+00:00   \n",
       "5915                       katharina seidler  2015-01-14 00:00:00+00:00   \n",
       "\n",
       "                                           text_cleaned  \n",
       "0     kinderwagen drngen eingangstr wolfgang puchers...  \n",
       "1     handbuch kolumnenschreiberei sieht letzte glos...  \n",
       "2     xenia fotografin 22 zwei jahren tag zuhause ge...  \n",
       "3     zuerst korrektur irrtums ama betrieb restauran...  \n",
       "4     wann feiert kabarettist eigentlich silvester a...  \n",
       "...                                                 ...  \n",
       "5911  konzept einfach schlssig zugereiste wiener mus...  \n",
       "5912  drei songs viereinhalb minuten lime crush setz...  \n",
       "5913  warum mssen menschen krieg elend flchten masse...  \n",
       "5914  sammler getriebene gilt fr bchersammler seit 1...  \n",
       "5915  kickdrum zischt dampft snares rollen triolen h...  \n",
       "\n",
       "[5916 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09844554-c290-4b40-bb6a-5b8a5acbf931",
   "metadata": {},
   "source": [
    "Retrieve the most relevant words for each article using TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139be16a-f5aa-4fe3-b77f-342942e5a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(merged[\"text_cleaned\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900f876-54a4-44d3-80f8-e83dc19fcb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature names\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Get IDF scores\n",
    "idf_scores = vectorizer.idf_\n",
    "\n",
    "# Combine feature names and IDF scores\n",
    "features_with_scores = list(zip(feature_names, idf_scores))\n",
    "\n",
    "# Sort the list based on IDF scores\n",
    "sorted_features = sorted(features_with_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Specify the number of top words to retrieve\n",
    "top_n = 100\n",
    "\n",
    "# Retrieve the top N words\n",
    "top_words = sorted_features[:top_n]\n",
    "\n",
    "# Print the top words and their IDF scores\n",
    "for word, score in top_words:\n",
    "    print(f\"Word: {word}, IDF Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25363636-2ea7-4e9d-9fd0-be629ebb65af",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "top_n = 250\n",
    "# Create an empty list to store the top words for each text\n",
    "top_words_per_text = []\n",
    "for i, text in enumerate(merged[\"text_cleaned\"]):\n",
    "    # Transform the text into a TF-IDF vector\n",
    "    tfidf_vector = vectorizer.transform([text])\n",
    "\n",
    "    # Get the TF-IDF scores for the text\n",
    "    tfidf_scores = zip(feature_names, tfidf_vector.toarray()[0])\n",
    "\n",
    "    # Sort the TF-IDF scores in descending order\n",
    "    sorted_scores = sorted(tfidf_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Retrieve the top N words for the text\n",
    "    top_words = [word for word, score in sorted_scores[:top_n]]\n",
    "\n",
    "    # Store the top words for the text in the dictionary\n",
    "    \n",
    "        # Combine the top words into a single string\n",
    "    top_words_text = ' '.join(top_words)\n",
    "\n",
    "    # Store the top words for the text in the list\n",
    "    top_words_per_text.append(top_words_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13d4ed3-70e8-450b-9d0f-764a26ebad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"Top_words\"] = top_words_per_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171c11ca-b15c-42f9-9721-6cc3229d1f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f041bdf-203f-4627-8612-ba4501891e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(\"../data/top_250.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "696d7aa3-fb48-4dac-8d5b-7bd86b8b41c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>ressort</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>Top_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FALTER_201512234F1D30CEA9</td>\n",
       "      <td>\"Bewundere Frau Merkel über alles\"</td>\n",
       "      <td>['Kinderwagen drängen sich bei der Eingangstür...</td>\n",
       "      <td>Steiermark</td>\n",
       "      <td>gerlinde pölsler</td>\n",
       "      <td>2015-12-23 00:00:00+00:00</td>\n",
       "      <td>kinderwagen drngen eingangstr wolfgang puchers...</td>\n",
       "      <td>pucher vinzidorf roma frauen pfarrhaus fr weih...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FALTER_2015122382119EA87A</td>\n",
       "      <td>Wildbretter</td>\n",
       "      <td>['Das Handbuch der Kolumnenschreiberei sieht v...</td>\n",
       "      <td>Falters Zoo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-12-23 00:00:00+00:00</td>\n",
       "      <td>handbuch kolumnenschreiberei sieht letzte glos...</td>\n",
       "      <td>vanillekipferln wildtier darf echt abfassen ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>FALTER_2015122317D031535C</td>\n",
       "      <td>Warum es ganz normal sein kann, zwei Zuhause z...</td>\n",
       "      <td>['Xenia, Fotografin, 22', 'Ich habe bis vor zw...</td>\n",
       "      <td>Stadtleben</td>\n",
       "      <td>barbara tóth</td>\n",
       "      <td>2015-12-23 00:00:00+00:00</td>\n",
       "      <td>xenia fotografin 22 zwei jahren tag zuhause ge...</td>\n",
       "      <td>vater wechselmodell eltern mutter zuhause dopp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>FALTER_20151223D853291AAA</td>\n",
       "      <td>Der Lerchenfisch</td>\n",
       "      <td>['Zuerst Korrektur eines Irrtums: Nicht die AM...</td>\n",
       "      <td>Stadtleben</td>\n",
       "      <td>florian holzer</td>\n",
       "      <td>2015-12-23 00:00:00+00:00</td>\n",
       "      <td>zuerst korrektur irrtums ama betrieb restauran...</td>\n",
       "      <td>eishken tel fisch austern fischgeschft estate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>FALTER_201512238A0DEB6E2D</td>\n",
       "      <td>Uhudler-Orbán und Kernölamazonen</td>\n",
       "      <td>['Wann feiert ein Kabarettist eigentlich Silve...</td>\n",
       "      <td>Lexikon</td>\n",
       "      <td>stefanie panzenböck, sara schausberger</td>\n",
       "      <td>2015-12-23 00:00:00+00:00</td>\n",
       "      <td>wann feiert kabarettist eigentlich silvester a...</td>\n",
       "      <td>silvester uhr kabarettist 2230 maurer special ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5911</th>\n",
       "      <td>5911</td>\n",
       "      <td>FALTER_20150114D1B1464B21</td>\n",
       "      <td>Achte Ausgabe des Festivals in between</td>\n",
       "      <td>['Das Konzept ist so einfach wie schlüssig: Zu...</td>\n",
       "      <td>Lexikon</td>\n",
       "      <td>gs</td>\n",
       "      <td>2015-01-14 00:00:00+00:00</td>\n",
       "      <td>konzept einfach schlssig zugereiste wiener mus...</td>\n",
       "      <td>between akzent angelacht baheux dreiteilig klo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5912</th>\n",
       "      <td>5912</td>\n",
       "      <td>FALTER_20150114100173AA99</td>\n",
       "      <td>Punkrock der Marke \"Ned deppert sein!\"</td>\n",
       "      <td>['Drei Songs in viereinhalb Minuten: Lime Crus...</td>\n",
       "      <td>Lexikon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-14 00:00:00+00:00</td>\n",
       "      <td>drei songs viereinhalb minuten lime crush setz...</td>\n",
       "      <td>219 lime crush mc deppert ned marke akademie h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>5913</td>\n",
       "      <td>FALTER_201501144F8F9DDBEE</td>\n",
       "      <td>Mit einem Flüchtling in der WG: Neue Initiativ...</td>\n",
       "      <td>['Warum müssen Menschen, die vor Krieg und Ele...</td>\n",
       "      <td>Politik</td>\n",
       "      <td>benedikt narodoslawsky</td>\n",
       "      <td>2015-01-14 00:00:00+00:00</td>\n",
       "      <td>warum mssen menschen krieg elend flchten masse...</td>\n",
       "      <td>zistl initiative flchtlinge asylwerber kontakt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>5914</td>\n",
       "      <td>FALTER_201501143FF6C01FA5</td>\n",
       "      <td>Büchersonntag in Hietzing</td>\n",
       "      <td>['Sammler sind Getriebene, das gilt auch für B...</td>\n",
       "      <td>Lexikon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-14 00:00:00+00:00</td>\n",
       "      <td>sammler getriebene gilt fr bchersammler seit 1...</td>\n",
       "      <td>hietzing bchersonntag vhs austriaca bchersamml...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>5915</td>\n",
       "      <td>FALTER_20150114D27133E690</td>\n",
       "      <td>Neuer Floor, neue Party: ein guter Start ins P...</td>\n",
       "      <td>['Die Kickdrum zischt und dampft, die Snares r...</td>\n",
       "      <td>Lexikon</td>\n",
       "      <td>katharina seidler</td>\n",
       "      <td>2015-01-14 00:00:00+00:00</td>\n",
       "      <td>kickdrum zischt dampft snares rollen triolen h...</td>\n",
       "      <td>music ikonika position bass club caf clubs cel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5916 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                 article_id  \\\n",
       "0              0  FALTER_201512234F1D30CEA9   \n",
       "1              1  FALTER_2015122382119EA87A   \n",
       "2              2  FALTER_2015122317D031535C   \n",
       "3              3  FALTER_20151223D853291AAA   \n",
       "4              4  FALTER_201512238A0DEB6E2D   \n",
       "...          ...                        ...   \n",
       "5911        5911  FALTER_20150114D1B1464B21   \n",
       "5912        5912  FALTER_20150114100173AA99   \n",
       "5913        5913  FALTER_201501144F8F9DDBEE   \n",
       "5914        5914  FALTER_201501143FF6C01FA5   \n",
       "5915        5915  FALTER_20150114D27133E690   \n",
       "\n",
       "                                                  title  \\\n",
       "0                    \"Bewundere Frau Merkel über alles\"   \n",
       "1                                           Wildbretter   \n",
       "2     Warum es ganz normal sein kann, zwei Zuhause z...   \n",
       "3                                      Der Lerchenfisch   \n",
       "4                      Uhudler-Orbán und Kernölamazonen   \n",
       "...                                                 ...   \n",
       "5911             Achte Ausgabe des Festivals in between   \n",
       "5912             Punkrock der Marke \"Ned deppert sein!\"   \n",
       "5913  Mit einem Flüchtling in der WG: Neue Initiativ...   \n",
       "5914                          Büchersonntag in Hietzing   \n",
       "5915  Neuer Floor, neue Party: ein guter Start ins P...   \n",
       "\n",
       "                                             paragraphs      ressort  \\\n",
       "0     ['Kinderwagen drängen sich bei der Eingangstür...   Steiermark   \n",
       "1     ['Das Handbuch der Kolumnenschreiberei sieht v...  Falters Zoo   \n",
       "2     ['Xenia, Fotografin, 22', 'Ich habe bis vor zw...   Stadtleben   \n",
       "3     ['Zuerst Korrektur eines Irrtums: Nicht die AM...   Stadtleben   \n",
       "4     ['Wann feiert ein Kabarettist eigentlich Silve...      Lexikon   \n",
       "...                                                 ...          ...   \n",
       "5911  ['Das Konzept ist so einfach wie schlüssig: Zu...      Lexikon   \n",
       "5912  ['Drei Songs in viereinhalb Minuten: Lime Crus...      Lexikon   \n",
       "5913  ['Warum müssen Menschen, die vor Krieg und Ele...      Politik   \n",
       "5914  ['Sammler sind Getriebene, das gilt auch für B...      Lexikon   \n",
       "5915  ['Die Kickdrum zischt und dampft, die Snares r...      Lexikon   \n",
       "\n",
       "                                     authors                       date  \\\n",
       "0                           gerlinde pölsler  2015-12-23 00:00:00+00:00   \n",
       "1                                        NaN  2015-12-23 00:00:00+00:00   \n",
       "2                               barbara tóth  2015-12-23 00:00:00+00:00   \n",
       "3                             florian holzer  2015-12-23 00:00:00+00:00   \n",
       "4     stefanie panzenböck, sara schausberger  2015-12-23 00:00:00+00:00   \n",
       "...                                      ...                        ...   \n",
       "5911                                      gs  2015-01-14 00:00:00+00:00   \n",
       "5912                                     NaN  2015-01-14 00:00:00+00:00   \n",
       "5913                  benedikt narodoslawsky  2015-01-14 00:00:00+00:00   \n",
       "5914                                     NaN  2015-01-14 00:00:00+00:00   \n",
       "5915                       katharina seidler  2015-01-14 00:00:00+00:00   \n",
       "\n",
       "                                           text_cleaned  \\\n",
       "0     kinderwagen drngen eingangstr wolfgang puchers...   \n",
       "1     handbuch kolumnenschreiberei sieht letzte glos...   \n",
       "2     xenia fotografin 22 zwei jahren tag zuhause ge...   \n",
       "3     zuerst korrektur irrtums ama betrieb restauran...   \n",
       "4     wann feiert kabarettist eigentlich silvester a...   \n",
       "...                                                 ...   \n",
       "5911  konzept einfach schlssig zugereiste wiener mus...   \n",
       "5912  drei songs viereinhalb minuten lime crush setz...   \n",
       "5913  warum mssen menschen krieg elend flchten masse...   \n",
       "5914  sammler getriebene gilt fr bchersammler seit 1...   \n",
       "5915  kickdrum zischt dampft snares rollen triolen h...   \n",
       "\n",
       "                                              Top_words  \n",
       "0     pucher vinzidorf roma frauen pfarrhaus fr weih...  \n",
       "1     vanillekipferln wildtier darf echt abfassen ad...  \n",
       "2     vater wechselmodell eltern mutter zuhause dopp...  \n",
       "3     eishken tel fisch austern fischgeschft estate ...  \n",
       "4     silvester uhr kabarettist 2230 maurer special ...  \n",
       "...                                                 ...  \n",
       "5911  between akzent angelacht baheux dreiteilig klo...  \n",
       "5912  219 lime crush mc deppert ned marke akademie h...  \n",
       "5913  zistl initiative flchtlinge asylwerber kontakt...  \n",
       "5914  hietzing bchersonntag vhs austriaca bchersamml...  \n",
       "5915  music ikonika position bass club caf clubs cel...  \n",
       "\n",
       "[5916 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.read_csv(\"../data/top_250.csv\")\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd078ce-dcc2-4fdf-be87-694222ed631b",
   "metadata": {},
   "source": [
    "## Tokenization and embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc6ead8-46df-4b1e-8226-aa9cdd22ed6c",
   "metadata": {},
   "source": [
    "### Cost estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a30d33c1-88d6-428c-9936-7afff8ae11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tiktoken\n",
    "import openai\n",
    "\n",
    "from openai.embeddings_utils import get_embedding\n",
    "\n",
    "# initialization and embedding model parameters\n",
    "openai.api_key='sdemo'\n",
    "\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "embedding_encoding = \"cl100k_base\"  # this the encoding for text-embedding-ada-002\n",
    "max_tokens = 8000  # the maximum for text-embedding-ada-002 is 8191\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ec5a0-40e7-4fbb-81ec-95d8b3211781",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(embedding_encoding)\n",
    "\n",
    "# omit reviews that are too long to embed\n",
    "merged[\"tokens\"] = merged[\"Top_words\"].apply(lambda x: encoding.encode(x))\n",
    "merged[\"n_tokens\"] = merged[\"tokens\"].apply(lambda x: len(x))\n",
    "#df = df[df.n_tokens <= max_tokens].tail(top_n)\n",
    "numb_tokens = merged[\"n_tokens\"].sum() # total number of tokens\n",
    "merged.head()\n",
    "#print(numb_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c358a6c-dfae-4128-9a8b-c657a5f26dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\tUsage\n",
    "# Ada v2 ---$0.0001 / 1K tokens\n",
    "# Ada v1 --- $0.0040 / 1K tokens\n",
    "cost_est = (numb_tokens/1000) * 0.0001\n",
    "print(f\"The total number of tokens for the top 100 words for each article is {numb_tokens} and that would cost {cost_est} EUR using Ada v2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b042bf1c-ce57-44cd-8385-bed9b319d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.Top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c930adcc-7aae-4bea-af3c-ad662fea8f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"bert-base-german-cased\")\n",
    "\n",
    "query_result = embeddings.embed_documents(merged.Top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a32adf9-19f4-47d9-af24-f0ad1a8cb43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"../data/huggingface_top250_embedding.pkl\"\n",
    "\n",
    "open_file = open(file_name, \"wb\")\n",
    "pickle.dump(query_result, open_file) \n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58356e2-cd1d-4cc9-8ba6-71af07b27fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import FakeEmbeddings\n",
    "fakeemb = FakeEmbeddings(size=768)\n",
    "embd = fakeemb.embed_documents(merged.Top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12384fa-a745-491d-bb85-016fce1a8682",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"../data/ fakeembedding_top250.pkl\"\n",
    "\n",
    "open_file = open(file_name, \"wb\")\n",
    "pickle.dump(query_result, open_file) \n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ebf0284-8fbb-4db0-96f7-ebf229ec9d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-7uMAe43mjF7WfaPGibZ4WDao on tokens per min. Limit: 1000000 / min. Current: 514311 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-7uMAe43mjF7WfaPGibZ4WDao on tokens per min. Limit: 1000000 / min. Current: 415921 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-7uMAe43mjF7WfaPGibZ4WDao on tokens per min. Limit: 1000000 / min. Current: 325629 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-7uMAe43mjF7WfaPGibZ4WDao on tokens per min. Limit: 1000000 / min. Current: 748641 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-7uMAe43mjF7WfaPGibZ4WDao on tokens per min. Limit: 1000000 / min. Current: 658709 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-7uMAe43mjF7WfaPGibZ4WDao on tokens per min. Limit: 1000000 / min. Current: 576300 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-7uMAe43mjF7WfaPGibZ4WDao on tokens per min. Limit: 1000000 / min. Current: 490453 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-7uMAe43mjF7WfaPGibZ4WDao on tokens per min. Limit: 1000000 / min. Current: 336793 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-7uMAe43mjF7WfaPGibZ4WDao on tokens per min. Limit: 1000000 / min. Current: 665150 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-7uMAe43mjF7WfaPGibZ4WDao on tokens per min. Limit: 1000000 / min. Current: 584408 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-7uMAe43mjF7WfaPGibZ4WDao on tokens per min. Limit: 1000000 / min. Current: 481364 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-7uMAe43mjF7WfaPGibZ4WDao on tokens per min. Limit: 1000000 / min. Current: 384812 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-7uMAe43mjF7WfaPGibZ4WDao on tokens per min. Limit: 1000000 / min. Current: 743226 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-7uMAe43mjF7WfaPGibZ4WDao on tokens per min. Limit: 1000000 / min. Current: 652087 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-7uMAe43mjF7WfaPGibZ4WDao on tokens per min. Limit: 1000000 / min. Current: 530521 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-7uMAe43mjF7WfaPGibZ4WDao on tokens per min. Limit: 1000000 / min. Current: 439341 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-7uMAe43mjF7WfaPGibZ4WDao on tokens per min. Limit: 1000000 / min. Current: 811981 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-7uMAe43mjF7WfaPGibZ4WDao on tokens per min. Limit: 1000000 / min. Current: 698959 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-7uMAe43mjF7WfaPGibZ4WDao on tokens per min. Limit: 1000000 / min. Current: 613839 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-7uMAe43mjF7WfaPGibZ4WDao on tokens per min. Limit: 1000000 / min. Current: 533817 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "openai = OpenAIEmbeddings(openai_api_key=\"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\")\n",
    "openai = openai.embed_documents(merged.Top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1a60edf-f15f-426f-8527-26e02bad1476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfile_name = \"../data/openaiembed_top250.pkl\"\\n\\nopen_file = open(file_name, \"wb\")\\npickle.dump(openai, open_file) # !!!!!!!!!!!!!!!!!!!!!!!!!should not it be openai instead query_results????\\nopen_file.close()\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "openai -- > 5916 -- for the 5915 articles\n",
    "openai[1] --> 1536 --- each article o\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "file_name = \"../data/openaiembed_top250.pkl\"\n",
    "\n",
    "open_file = open(file_name, \"wb\")\n",
    "pickle.dump(openai, open_file) # !!!!!!!!!!!!!!!!!!!!!!!!!should not it be openai instead query_results????\n",
    "open_file.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48bcae8e-2caa-4e53-821b-5d1aad322529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       pucher vinzidorf roma frauen pfarrhaus fr weih...\n",
       "1       vanillekipferln wildtier darf echt abfassen ad...\n",
       "2       vater wechselmodell eltern mutter zuhause dopp...\n",
       "3       eishken tel fisch austern fischgeschft estate ...\n",
       "4       silvester uhr kabarettist 2230 maurer special ...\n",
       "                              ...                        \n",
       "5911    between akzent angelacht baheux dreiteilig klo...\n",
       "5912    219 lime crush mc deppert ned marke akademie h...\n",
       "5913    zistl initiative flchtlinge asylwerber kontakt...\n",
       "5914    hietzing bchersonntag vhs austriaca bchersamml...\n",
       "5915    music ikonika position bass club caf clubs cel...\n",
       "Name: Top_words, Length: 5916, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.Top_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
