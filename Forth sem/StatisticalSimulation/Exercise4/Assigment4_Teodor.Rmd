---
title: "Sample distribution and Central Limit Theorem"
author: "Teodor Chakarov"
date: "2023-11-08"
output:
  pdf_document:
    latex_engine: xelatex
    toc: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = TRUE}
set.seed(12141198)
```


# Task 1 - Mean and median values form samples and Central Limit Theorem role
We have been given the following samples:
```{r}
sample <- c(4.94, 5.06, 4.53, 5.07, 4.99, 5.16, 4.38, 4.43, 4.93, 4.72, 4.92, 4.96)
```

## How many possible bootstrap samples are there, if each bootstrap sample has the same size as the original?

We generate a bootstrap sample of size n=12 from a given sample of size N=12. Since the values are allowed to repeat and the order does not matter, the formula for this is 
In case when the order and repetitiveness of the values doesn't matter, we have the following formula for sample size of 12:
$\text{Number of boostrap samples} = {2n + 1\choose n} = {25 \choose 12} = 5200300$

## Compute the mean and the median of the original sample.

Mean and median values of our samples are:
```{r}
mean <- mean(sample)
sample_median <- median(sample)

print(paste0("Mean: ", mean))
print(paste0("Median: ", sample_median))
```

## Create 2000 bootstrap samples and compute their means. 
Lets create 2000 samples from our given one:
```{r}
set.seed(12141198)

list_means = list()
for (i in 1:2000){
  bootstrap_mean = mean(sample(sample,12,replace=TRUE))
  list_means <- append(list_means, bootstrap_mean)
}

```

This function will perform our mean computation baes on the number of samples we want.
```{r}
compute_mean <- function(nth_sample) {
  mean <- mean(unlist(list_means[1:nth_sample]))
  print(paste0("Mean ",  nth_sample, " bootstrap samples: ", mean))
}
```

1. Compute the mean on the first 20 bootstrap means.

```{r}
compute_mean(20)
```

```{r}
compute_mean(20)
```

2. Compute the mean on the first 200 bootstrap means.

```{r}
compute_mean(200)
```

3. Compute the mean based on all 2000 bootstrap means.

```{r}
compute_mean(2000)
```

4. Visualize the distribution all the different bootstrap means to the sample mean.

```{r}
hist(unlist(list_means[1:2000]),  breaks=30, main="Mean distribution of our samples", xlab="Mean values")
abline(v=mean, col="red")
```

As we see based on the histplot we have normal distribution and should be expected based on the theorem. As more representations we have, the more normal distributed values we will have.


5. Based on the three different bootstrap sample lengths in 3. compute the corresponding 0.025 and 0.975 quantiles. Compare the three resulting intervals against each other and the "true" confidence interval of the mean under the assumption of normality.

True confidence interval
```{r}
true_conf_int <- t.test(sample, conf.level = 0.95)$conf.int
print(paste0("Conf. interval: ", true_conf_int[1], ", ", true_conf_int[2]))
```

Confidence intervals for sample lengths of 20, 200 and 2000

```{r}
values <- c(20, 200, 2000)

for (val in values) {
  conf_int <- c(quantile(unlist(list_means[1:val]), 0.025), quantile(unlist(list_means[1:val]), 0.975))
  print(paste0("Confidence interval for first ", val, " means: [", conf_int[1], ", ", conf_int[2], "]"))
}
```

The confidence interval of our original sample tested with t-test is wider than the ones resulted from 20,200 or 2000 means. Which increasing size of means used to compute the confidence intervals they shift down.


## Create 2000 bootstrap samples and compute their medians. 
Now we will see the median for the statistics.

This function will perform our median computation based on the number of samples we want.
```{r}
compute_median <- function(nth_sample) {
  median <- median(unlist(list_means[1:nth_sample]))
  print(paste0("Median ",  nth_sample, " bootstrap samples: ", median))
}
```


```{r}
set.seed(12141198)

list_medians = list()
for (i in 1:2000){
  bootstrap_sample_median = median(sample(sample,12,replace=TRUE))
  list_medians <- append(list_medians, bootstrap_sample_median)
}
```


1. Compute the mean on the first 20 bootstrap medians.

```{r}
compute_median(20)
```

2. Compute the mean of the first 200 bootstrap medians.

```{r}
compute_median(200)
```

3. Compute the mean based on all 2000 bootstrap medians.

```{r}
compute_median(2000)
```

4. Visualize the distribution all the different bootstrap medians to the sample median.

```{r}
hist(unlist(list_medians[1:2000]),  breaks=30, main="Medain distribution of our samples", xlab="Medain values")
abline(v=sample_median, col="red")
```

We can see that based on the histogram, our distribution is not so normal distributed, based on the right shift, but if we see the median values they are pretty close from 4.8 to 5.0


5. Based on the three different bootstrap sample lengths in 3. compute the corresponding 0.025 and 0.975 quantiles. Compare the three resulting intervals against each other.
Confidence intervals based on the given sample is:
```{r}
true_conf_int <- t.test(sample, conf.level = 0.95)$conf.int
print(paste0("Conf. interval: ", true_conf_int[1], ", ", true_conf_int[2]))
```

Confidence intervals for sample lengths of 20, 200 and 2000
```{r}
n_values <- c(20, 200, 2000)
for (n in n_values) {
  conf_interval <- c(quantile(unlist(list_medians[1:n]),0.025),quantile(unlist(list_medians[1:n]),0.975))
  print(paste0("Confidence interval for ", n, " medians: ", conf_interval[1], ", ", conf_interval[2]))
}

```

The confidence intervals are almost the same when we compared from our initial from the t-test we performed. From the t-test is a little bit smaller when we compare the upper bound but ion general, its performing reasonable.


# Task 2 - Effect of outliers

## 1. Set your seed to 1234. And then sample 1960 points from a standard normal distribution to create the vector x.clean then sample 40 observations from uniform(4,5) and denote them as x.cont. The total data is x <- c(x.clean,x.cont). After creating the sample set your seed to your immatriculation number.

```{r}
set.seed(1234)
x.clean <- rnorm(1960)
x.cont <- runif(40,4,5)
x <- c(x.clean,x.cont) 
set.seed(12141198)
```

## 2. Estimate the median, the mean and the trimmed mean with alpha = 0.05 for x and x.clean.

```{r}
sample_mean <- mean(x)
sample_median <- median(x)
sample_trim_mean <- mean(x, trim=0.05)

sample_clean_mean <- mean(x.clean)
sample_clean_median <- median(x.clean)
sample_clean_trim_mean <- mean(x.clean, trim=0.05)
```

We can see the values compared in the table:

sample  | median | mean | trimed mean
------- | ------ | ---- | ----------- 
x       | `r sample_median`| `r sample_mean` | `r sample_trim_mean`
x.clean | `r sample_clean_median`| `r sample_clean_mean` | `r sample_clean_trim_mean`


## 3.  Use nonparametric bootstrap (for x and x.clean) to calculate the standard error and the 95 percentile CI of all 3 estimators.
To estimate the standard error of (a univariate) theta using nonparametric bootstrap the standard deviation of the bootstrap estimates is used:

Calculating Means 
```{r}
itters <- 2000
set.seed(12141198)


sampleSamples <- replicate(itters, sample(x, size=2000, replace=TRUE))
x.cleanSamples <- replicate(itters, sample(x.clean, size=2000, replace=TRUE))

meanEstimates <- numeric(itters)
meanEstimatesClean <- numeric(itters)


for(iter in 1:itters){
  meanEstimates[iter] <- mean(sampleSamples[,iter])
}

for(iter in 1:itters){
  meanEstimatesClean[iter] <- mean(x.cleanSamples[,iter])
}
```

Calculating Standard Error
```{r}
sterror <- function(data, itterations=itters) {
  err <- sqrt(1 / (itterations - 1) * sum((data - (mean(data)))^2))
  
  return(err)
}

errX <- sterror(meanEstimates)
errClean <- sterror(meanEstimatesClean)

errX
errClean
```

Confidence Intervals 
```{r}
alpha <- 0.05
beta <- 1 - alpha

conf_inter_means = c(
  quantile(meanEstimates, alpha), quantile(meanEstimates, beta),
  quantile(meanEstimatesClean, alpha), quantile(meanEstimatesClean, beta)
)

```


Medians calculation
```{r}
medianEstimates <- numeric(itters)
for (iter in 1:itters) {
  medianEstimates[iter] <- median(sampleSamples[,iter])
}

medianEstimatesClean <- numeric(itters)
for (iter in 1:itters) {
  medianEstimatesClean[iter] <- median(x.cleanSamples[,iter])
}
```

Trimmed Mean calculation
```{r}
trimmedMeanEstimates <- numeric(itters)
for (iter in 1:itters) {
  trimmedMeanEstimates[iter] <- mean(sampleSamples[,iter], trim=0.05)
}
trimmedMeanEstimates

trimmedMeanEstimatesClean <- numeric(itters)
for (iter in 1:itters) {
  trimmedMeanEstimatesClean[iter] <- mean(x.cleanSamples[,iter], trim=0.05)
}
trimmedMeanEstimatesClean
```

Confidence Intervals 
```{r}
conf_inter_medians = c(
  quantile(medianEstimates, alpha), quantile(medianEstimates, beta),
  quantile(medianEstimatesClean, alpha), quantile(medianEstimatesClean, beta))

ciTrimmedMeanEstimates = c(
  quantile(trimmedMeanEstimates, alpha), quantile(trimmedMeanEstimates, beta),
  quantile(trimmedMeanEstimatesClean, alpha), quantile(trimmedMeanEstimatesClean, beta))
```

```{r}
estimationTable <- data.frame(
    DataSample=c('sample', 'x.clean'),
    StdError=c(errX, errClean),
    CIMeanLower=c(conf_inter_means[1], conf_inter_means[3]),
    CIMeanUpper=c(conf_inter_means[2], conf_inter_means[4]),
    CIMedianLower=c(conf_inter_medians[1], conf_inter_medians[3]),
    CIMedianUpper=c(conf_inter_medians[2], conf_inter_medians[4]),
    CITrimMeanLower=c(ciTrimmedMeanEstimates[1], ciTrimmedMeanEstimates[3]),
    CITrimMeanUpper=c(ciTrimmedMeanEstimates[2], ciTrimmedMeanEstimates[4])
)

```

```{r}
estimationTable
```


## 4 Use parametric bootstrap (based on x and x.clean) to calculate: - bias - standard error - 95 percentile CI - bias corrected estimate for the mean and the trimed mean 
In a parametric bootstrap, we assume our data follow a normal distribution and we can create samples from $N(\bar{x},s_n^2)$

```{r}
#Original values  
mean_x <- mean(x)
mean_x_clean <- mean(x.clean)

sd_x <- sd(x)
sd_x_clean <- sd(x.clean)
tr_mean_x <- mean(x, trim=0.05)
tr_mean_x_clean <- mean(x.clean, trim=0.05)

```

Mean and sample creation
```{r}
samples_x <- replicate(itters, rnorm(length(x), mean=mean_x, sd=sd_x))
means_x <- numeric(itters)
for (i in 1:itters) {
  means_x[i] <- mean(samples_x[,i])
}

samples_x_clean <- replicate(itters, rnorm(2000, mean=mean_x_clean, sd=sd_x_clean))
means_x_clean <- numeric(length(samples_x_clean))

for (i in 1:itters) {
  means_x_clean[i] <- mean(samples_x_clean[,i])
}
```

Standard error
```{r}
st_err_x <- sterror(means_x)
st_err_x_clean <- sterror(means_x_clean)

st_err_x
st_err_x_clean
```

Confidence interval
```{r}
alpha <- 0.05
beta <- 1 - alpha
ci_mean = c(
  quantile(means_x, alpha), quantile(means_x, beta),
  quantile(means_x_clean, alpha), quantile(means_x_clean, beta)
)

medians_x <- numeric(itters)
for (i in 1:itters) {
  means_x[i] <- median(samples_x[,i])
  }
medians_x_clean <- numeric(itters)

for (i in 1:itters) {
  means_x_clean[i] <- median(samples_x_clean[,i])
  }
tr_mean_x <- numeric(itters)

for (i in 1:itters) {
  tr_mean_x[i] <- mean(samples_x[,i], trim=0.05)
  }
tr_mean_x_clean <- numeric(itters)

for (i in 1:itters) {
  tr_mean_x_clean[i] <- mean(samples_x_clean[,i], trim=0.05)
}
```

```{r}
ci_median = c(
  quantile(medians_x, alpha), quantile(medians_x, beta),
  quantile(medians_x_clean, alpha), quantile(medians_x_clean, beta))

ci_trimmean = c(
  quantile(tr_mean_x, alpha), quantile(tr_mean_x, beta),
  quantile(tr_mean_x_clean, alpha), quantile(tr_mean_x_clean, beta))

bias_mean_x <- mean(means_x) - mean_x
bias_trim_mean_x <- mean(tr_mean_x) - tr_mean_x
bias_mean_x_clean <- mean(means_x_clean) - mean_x_clean
bias_trim_mean_x_clean <- mean(tr_mean_x_clean) - tr_mean_x_clean
```

## 5 Compare and summarize your findings with tables and graphically

```{r}
estimationTable <- data.frame(
    DataSample=c('x', 'x.clean'),
    StdError=c(st_err_x, sd_x_clean),
    CIMeanLower=c(ci_mean[1], ci_mean[3]),
    CIMeanUpper=c(ci_mean[2], ci_mean[4]),
    CIMedianLower=c(ci_median[1], ci_median[3]),
    CIMedianUpper=c(ci_median[2], ci_median[4]),
    CITrimMeanLower=c(ci_trimmean[1], ci_trimmean[3]),
    CITrimMeanUpper=c(ci_trimmean[2], ci_trimmean[4])
)
```

```{r}
estimationTable
```

The dataset x seems to have stable means and medians with values mostly around the range 0.04007788 to 0.1264562. x.clean have a higher variability, especially considering its larger standard error. The trimmed mean of x.clean suggests that when outliers or extreme values are removed, the central values are around -0.04481158 to 0.0303291.
It's worth noting that these interpretations should be considered in the context of the broader research or the nature of the data, and further analyses might be needed to draw more concrete conclusions.

# Task 3 - Methodology of Bootstrapping

Bootstrapping is a powerful resampling method where samples are repetitively drawn from a given dataset. From this exercise, its shown that the non-parametric approach to bootstrapping directly resamples observed data without making any strict assumptions regarding the population distribution's shape. On the other hand, the parametric bootstrap method first estimates parameters, such as the mean, from the original data. Bootstrap samples are then generated based on these derived parameters. This technique often work with different distributional assumptions, e.g. the data being normally distributed. When constructing confidence intervals using bootstrap method, the procedure involves numerous samples with replacement. The desired statistic is computed for each of these samples. The distribution of these statistics then serves as the foundation upon which confidence intervals are established.
